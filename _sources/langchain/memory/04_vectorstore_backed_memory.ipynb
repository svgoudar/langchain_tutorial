{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4776c0",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## VectorStore-Backed Memory \n",
    "\n",
    "\n",
    "**VectorStore-backed memory** stores conversation snippets or facts as **embeddings in a vector database** and retrieves **only semantically relevant past context** when needed.\n",
    "\n",
    "Instead of replaying or summarizing chat history, the system **searches memory by meaning**.\n",
    "\n",
    "Provided via memory integrations in LangChain.\n",
    "\n",
    "```\n",
    "Conversation → Embeddings → Vector Store\n",
    "                         ↓\n",
    "                Semantic Retrieval\n",
    "                         ↓\n",
    "                    Prompt Context\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Why VectorStore-Backed Memory Exists\n",
    "\n",
    "Other memory types have limitations:\n",
    "\n",
    "* Buffer → token explosion\n",
    "* Window → hard forgetting\n",
    "* Summary → loss of detail\n",
    "\n",
    "VectorStore-backed memory solves this by:\n",
    "\n",
    "* Persisting **long-term memory**\n",
    "* Retrieving **only relevant information**\n",
    "* Scaling to **thousands of interactions**\n",
    "\n",
    "---\n",
    "\n",
    "### How It Works Internally\n",
    "\n",
    "1. Important messages are embedded\n",
    "2. Embeddings are stored in a vector database\n",
    "3. On each query:\n",
    "\n",
    "   * User input is embedded\n",
    "   * Similar memories are retrieved\n",
    "4. Retrieved memories are injected into the prompt\n",
    "\n",
    "```\n",
    "User Query → Embed → Similarity Search → Relevant Memories → LLM\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Architecture View\n",
    "\n",
    "![Image](https://cdn.sanity.io/images/vr8gru94/production/606382d0ca90a8d24f26780f5f9954123e37be91-575x603.png?utm_source=chatgpt.com)\n",
    "\n",
    "![Image](https://media.licdn.com/dms/image/v2/D5612AQHEiId0Px5-tQ/article-cover_image-shrink_720_1280/article-cover_image-shrink_720_1280/0/1687118588162?e=2147483647\\&t=KzhNS7LpNtTXfePlalOYfsD2PI45CB8OexuiUdSkhIY\\&v=beta\\&utm_source=chatgpt.com)\n",
    "\n",
    "![Image](https://www.cognee.ai/content/blog/posts/from-demo-to-production-1/atkinson.png?utm_source=chatgpt.com)\n",
    "\n",
    "---\n",
    "\n",
    "### VectorStore-Backed Memory Demonstration\n",
    "\n",
    "Using:\n",
    "\n",
    "* Chroma\n",
    "* LangChain embeddings + memory wrapper\n",
    "\n",
    "---\n",
    "\n",
    "### Create a Vector Store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9272ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"conversation_memory\",\n",
    "    embedding_function=embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848fe0d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Create VectorStore-Backed Memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505251d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sangouda\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangouda\\AppData\\Local\\Temp\\ipykernel_41888\\4110976946.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = VectorStoreRetrieverMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "memory = VectorStoreRetrieverMemory(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f25344",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This memory:\n",
    "\n",
    "* Stores text as vectors\n",
    "* Retrieves top-k semantically similar memories\n",
    "\n",
    "---\n",
    "\n",
    "### Attach Memory to a Chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cf6741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangouda\\AppData\\Local\\Temp\\ipykernel_41888\\3814521186.py:5: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use `langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.chains.conversation.base import ConversationChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc46ec",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Run a Conversation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c5bff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" From the information you have provided, it seems like you are facing connectivity issues with your VPN on Windows 11. This could be due to compatibility or configuration issues. It's best to check for updates and make sure your system meets the requirements. If the problem persists, reaching out to customer support would be the next step.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"My VPN disconnects every 5 minutes\")\n",
    "conversation.predict(input=\"It happens on Windows 11\")\n",
    "conversation.predict(input=\"What issue am I facing?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0949d209",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Expected Output**\n",
    "\n",
    "```\n",
    "You are facing a VPN connectivity issue on Windows 11 with frequent disconnections.\n",
    "```\n",
    "\n",
    "The model retrieved **relevant past facts** via semantic similarity.\n",
    "\n",
    "---\n",
    "\n",
    "### What Gets Stored in Vector Memory\n",
    "\n",
    "Each memory entry:\n",
    "\n",
    "```\n",
    "Text: \"VPN disconnects every 5 minutes on Windows 11\"\n",
    "Embedding: [0.012, 0.98, ...]\n",
    "Metadata: { \"timestamp\": \"...\", \"source\": \"conversation\" }\n",
    "```\n",
    "\n",
    "Unlike buffers:\n",
    "\n",
    "* Memory is **searchable**\n",
    "* Order is **not required**\n",
    "* Scale is **unbounded**\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt Injection Mechanism\n",
    "\n",
    "The prompt contains only retrieved memories:\n",
    "\n",
    "```\n",
    "System: You are a helpful assistant.\n",
    "\n",
    "Relevant Past Information:\n",
    "- VPN disconnects every 5 minutes on Windows 11\n",
    "\n",
    "Human: What issue am I facing?\n",
    "AI:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Strengths of VectorStore-Backed Memory\n",
    "\n",
    "* Long-term memory\n",
    "* Semantic recall\n",
    "* Token-efficient\n",
    "* Scales to large histories\n",
    "* Ideal for personalization\n",
    "\n",
    "---\n",
    "\n",
    "### Limitations\n",
    "\n",
    "| Limitation         | Explanation                    |\n",
    "| ------------------ | ------------------------------ |\n",
    "| Approximate recall | Similarity ≠ exact             |\n",
    "| Embedding cost     | Each memory requires embedding |\n",
    "| Latency            | Vector search adds overhead    |\n",
    "| No chronology      | Time order not guaranteed      |\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use VectorStore-Backed Memory\n",
    "\n",
    "Use it when:\n",
    "\n",
    "* Long-term user context matters\n",
    "* You need semantic recall\n",
    "* Conversations span days/weeks\n",
    "* Personalization is required\n",
    "\n",
    "Avoid it when:\n",
    "\n",
    "* Exact wording matters\n",
    "* Strict ordering is required\n",
    "* Conversations are short\n",
    "\n",
    "---\n",
    "\n",
    "### Comparison with Other Memory Types\n",
    "\n",
    "| Memory Type        | Storage      | Recall Type | Scale |\n",
    "| ------------------ | ------------ | ----------- | ----- |\n",
    "| Buffer             | Raw text     | Sequential  | ❌     |\n",
    "| Window             | Raw text     | Recent      | ❌     |\n",
    "| Summary            | Text summary | Approximate | ⚠️    |\n",
    "| VectorStore-Backed | Embeddings   | Semantic    | ✅     |\n",
    "\n",
    "---\n",
    "\n",
    "### Real-World Use Case\n",
    "\n",
    "**Production IT Support Agent**\n",
    "\n",
    "* Stores user environment details\n",
    "* Remembers recurring issues\n",
    "* Retrieves relevant past incidents\n",
    "* Works across sessions and devices\n",
    "\n",
    "Often combined with:\n",
    "\n",
    "* Summary memory (conversation flow)\n",
    "* Database memory (structured facts)\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* VectorStore-backed memory provides **semantic long-term memory**\n",
    "* It scales far beyond context windows\n",
    "* Ideal for personalization and continuity\n",
    "* Core building block for production agentic AI\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
