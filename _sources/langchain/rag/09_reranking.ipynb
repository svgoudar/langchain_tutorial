{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c3d978",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Reranking\n",
    "\n",
    "### What Reranking Is\n",
    "\n",
    "**Reranking** is a **second-stage retrieval step** that **reorders candidate documents** using a **more accurate but more expensive model** after an initial retrieval step.\n",
    "\n",
    "> First retrieve fast and broad, then rerank slow and precise.\n",
    "\n",
    "Reranking significantly improves **answer quality** and **reduces hallucinations**.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Reranking Is Needed\n",
    "\n",
    "Initial retrieval (vector / hybrid search):\n",
    "\n",
    "* Optimized for speed\n",
    "* Approximate\n",
    "* No deep query–document interaction\n",
    "\n",
    "Reranking:\n",
    "\n",
    "* Uses deep semantic matching\n",
    "* Considers query + document together\n",
    "* Produces higher precision results\n",
    "\n",
    "---\n",
    "\n",
    "### Where Reranking Fits in RAG\n",
    "\n",
    "```\n",
    "User Query\n",
    "   ↓\n",
    "Initial Retrieval (Vector / Hybrid)\n",
    "   ↓\n",
    "Top-N Candidates (e.g., 20)\n",
    "   ↓\n",
    "Reranker (Cross-Encoder)\n",
    "   ↓\n",
    "Top-K Results (e.g., 5)\n",
    "   ↓\n",
    "LLM\n",
    "```\n",
    "\n",
    "Reranking happens at **query time**.\n",
    "\n",
    "---\n",
    "\n",
    "### Core Idea (Two-Stage Retrieval)\n",
    "\n",
    "| Stage   | Purpose   | Model Type               |\n",
    "| ------- | --------- | ------------------------ |\n",
    "| Stage 1 | Recall    | Bi-encoder (embeddings)  |\n",
    "| Stage 2 | Precision | Cross-encoder (reranker) |\n",
    "\n",
    "---\n",
    "\n",
    "### How Reranking Works\n",
    "\n",
    "### Bi-Encoder (Retriever)\n",
    "\n",
    "* Query and documents embedded separately\n",
    "* Fast ANN search\n",
    "* Coarse ranking\n",
    "\n",
    "---\n",
    "\n",
    "### Cross-Encoder (Reranker)\n",
    "\n",
    "* Query and document passed **together**\n",
    "* Deep semantic scoring\n",
    "* Accurate ranking\n",
    "* Much slower\n",
    "\n",
    "Example input to reranker:\n",
    "\n",
    "```\n",
    "[QUERY] How to reset Jira password?\n",
    "[DOC] Password reset steps for Jira admin users...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Types of Rerankers\n",
    "\n",
    "### 1. Cross-Encoder Models (Most Common)\n",
    "\n",
    "* BERT-style models\n",
    "* Input: (query, document)\n",
    "* Output: relevance score\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Cohere Rerank\n",
    "* BGE Reranker\n",
    "* Cross-Encoder MiniLM\n",
    "\n",
    "---\n",
    "\n",
    "### 2. LLM-Based Reranking\n",
    "\n",
    "Uses an LLM to:\n",
    "\n",
    "* Score relevance\n",
    "* Select best chunks\n",
    "* Justify ranking\n",
    "\n",
    "More accurate, but:\n",
    "\n",
    "* Higher latency\n",
    "* Higher cost\n",
    "\n",
    "---\n",
    "\n",
    "### Reranking Demonstration (LangChain)\n",
    "\n",
    "#### Step 1: Initial Retrieval\n",
    "\n",
    "```python\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 20}\n",
    ")\n",
    "\n",
    "docs = retriever.get_relevant_documents(\n",
    "    \"How does Jira ticket escalation work?\"\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2: Rerank Documents\n",
    "\n",
    "```python\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "reranker = CrossEncoderReranker(\n",
    "    model=HuggingFaceCrossEncoder(\n",
    "        model_name=\"BAAI/bge-reranker-base\"\n",
    "    ),\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "reranked_docs = reranker.compress_documents(\n",
    "    docs,\n",
    "    query=\"How does Jira ticket escalation work?\"\n",
    ")\n",
    "```\n",
    "\n",
    "Only top 5 remain.\n",
    "\n",
    "---\n",
    "\n",
    "#### Reranking with Contextual Compression\n",
    "\n",
    "Reranking is often part of **Contextual Compression**:\n",
    "\n",
    "```\n",
    "Retriever → Reranker → LLM\n",
    "```\n",
    "\n",
    "LangChain abstraction:\n",
    "\n",
    "```python\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever=retriever,\n",
    "    base_compressor=reranker\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Reranking vs MMR\n",
    "\n",
    "| Aspect        | Reranking     | MMR       |\n",
    "| ------------- | ------------- | --------- |\n",
    "| Purpose       | Precision     | Diversity |\n",
    "| Model         | Cross-encoder | Heuristic |\n",
    "| Cost          | High          | Low       |\n",
    "| Used together | ✅             | ✅         |\n",
    "\n",
    "---\n",
    "\n",
    "### Reranking vs Similarity Thresholds\n",
    "\n",
    "| Aspect           | Reranking | Threshold |\n",
    "| ---------------- | --------- | --------- |\n",
    "| Accuracy         | High      | Low       |\n",
    "| Adaptive         | Yes       | No        |\n",
    "| Production-grade | ✅         | ❌         |\n",
    "\n",
    "---\n",
    "\n",
    "### Production-Grade Reranking Concepts\n",
    "\n",
    "### 1. Candidate Size (N)\n",
    "\n",
    "Typical:\n",
    "\n",
    "* Retrieve N = 20–50\n",
    "* Rerank to K = 3–10\n",
    "\n",
    "Tradeoff:\n",
    "\n",
    "* Larger N → better recall\n",
    "* Higher cost\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Latency Budget\n",
    "\n",
    "Typical:\n",
    "\n",
    "* Reranking: 50–200 ms\n",
    "* Total RAG: < 500 ms\n",
    "\n",
    "Optimization:\n",
    "\n",
    "* Batch reranker calls\n",
    "* Use smaller cross-encoders\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Cost Control\n",
    "\n",
    "Strategies:\n",
    "\n",
    "* Only rerank when confidence is low\n",
    "* Skip reranking for short queries\n",
    "* Cache reranker results\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Metadata-Aware Reranking\n",
    "\n",
    "Filter first, rerank later:\n",
    "\n",
    "```python\n",
    "filter={\"source\": \"jira\"}\n",
    "```\n",
    "\n",
    "Reduces reranker load.\n",
    "\n",
    "---\n",
    "\n",
    "### Common Mistakes\n",
    "\n",
    "#### Reranking everything\n",
    "\n",
    "❌ Unnecessary cost\n",
    "\n",
    "#### Too few initial candidates\n",
    "\n",
    "❌ Misses relevant context\n",
    "\n",
    "#### Large documents\n",
    "\n",
    "❌ Reranker context overflow\n",
    "\n",
    "#### No reranking in prod\n",
    "\n",
    "❌ Noisy LLM context\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use Reranking\n",
    "\n",
    "* Enterprise RAG\n",
    "* IT support / ticketing\n",
    "* Legal / compliance docs\n",
    "* Precision-critical QA\n",
    "\n",
    "---\n",
    "\n",
    "### When NOT to Use Reranking\n",
    "\n",
    "* Small datasets\n",
    "* Low-traffic prototypes\n",
    "* Exploratory search\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "* Use hybrid search before reranking\n",
    "* Keep chunk size small\n",
    "* Limit top-N\n",
    "* Monitor precision gains\n",
    "* Log reranking decisions\n",
    "\n",
    "---\n",
    "\n",
    "### Interview-Ready Summary\n",
    "\n",
    "> “Reranking is a second-stage retrieval step that reorders initially retrieved documents using a more accurate cross-encoder or LLM. It improves precision and answer quality in production RAG systems.”\n",
    "\n",
    "---\n",
    "\n",
    "### Rule of Thumb\n",
    "\n",
    "* **Retriever = recall**\n",
    "* **Reranker = precision**\n",
    "* **LLM = reasoning**\n",
    "* **Production RAG = all three**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
