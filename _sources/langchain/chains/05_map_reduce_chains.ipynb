{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eebf6c76",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## MapReduce Chain\n",
    "\n",
    "### What a MapReduce Chain Is\n",
    "\n",
    "A **MapReduce Chain** is a LangChain abstraction designed to **process large inputs by splitting them into chunks**, handling each chunk independently (**Map phase**), and then **combining the partial results into a final answer** (**Reduce phase**).\n",
    "\n",
    "> It is inspired by the classic **MapReduce** pattern used in distributed systems.\n",
    "\n",
    "This chain is commonly used for **summarization, analysis, and aggregation** over large documents.\n",
    "\n",
    "---\n",
    "\n",
    "### Why MapReduce Chain Exists\n",
    "\n",
    "LLMs have **context window limits**.\n",
    "Large documents cannot be processed in a single prompt.\n",
    "\n",
    "MapReduce solves this by:\n",
    "\n",
    "* Scaling to large inputs\n",
    "* Avoiding context overflow\n",
    "* Enabling parallel processing\n",
    "* Improving reliability on long texts\n",
    "\n",
    "---\n",
    "\n",
    "### Conceptual Flow\n",
    "\n",
    "```\n",
    "Large Input\n",
    "   ↓\n",
    "Split into chunks\n",
    "   ↓\n",
    "Map: Process each chunk independently\n",
    "   ↓\n",
    "Reduce: Combine partial results\n",
    "   ↓\n",
    "Final Output\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Core Phases Explained\n",
    "\n",
    "### Map Phase\n",
    "\n",
    "* Each chunk is sent to the LLM independently\n",
    "* Produces partial outputs (e.g., summaries, insights)\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Chunk 1 → Summary 1\n",
    "Chunk 2 → Summary 2\n",
    "Chunk 3 → Summary 3\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Reduce Phase\n",
    "\n",
    "* All partial outputs are combined\n",
    "* LLM synthesizes a final result\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "[Summary 1, Summary 2, Summary 3] → Final Summary\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Basic MapReduce Chain Demonstration\n",
    "\n",
    "#### Step 1: Define Map Prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd24a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "map_prompt = PromptTemplate.from_template(\n",
    "    \"Summarize the following text:\\n{text}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbafc52",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2: Define Reduce Prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa47875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_prompt = PromptTemplate.from_template(\n",
    "    \"Combine the following summaries into a concise final summary:\\n{text}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369661ea",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3: Create the MapReduce Chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0544ea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sangouda\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.chains.summarize import load_summarize_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    map_prompt=map_prompt,\n",
    "    combine_prompt=reduce_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c19032",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### Step 4: Run the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "492eb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create sample documents\n",
    "documents = [\n",
    "    Document(page_content=\"Artificial Intelligence is transforming industries worldwide. Machine learning algorithms enable computers to learn from data and improve their performance over time without explicit programming.\"),\n",
    "    Document(page_content=\"Natural Language Processing allows machines to understand and generate human language. Applications include chatbots, translation services, and sentiment analysis.\"),\n",
    "    Document(page_content=\"Computer vision enables machines to interpret and understand visual information from the world. It powers technologies like facial recognition, autonomous vehicles, and medical image analysis.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "722fd6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is transforming industries through machine learning algorithms that enable computers to autonomously improve their performance. Key areas of AI include Natural Language Processing (NLP), which allows machines to understand and generate human language for applications like chatbots and translation services, and computer vision, which enables the interpretation of visual information for technologies such as facial recognition and autonomous vehicles.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"input_documents\": documents})\n",
    "print(result[\"output_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de685e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here:\n",
    "\n",
    "* `documents` is a list of `Document` objects\n",
    "* Each document is processed in the map phase\n",
    "\n",
    "---\n",
    "\n",
    "### Internal Execution (Simplified)\n",
    "\n",
    "```\n",
    "for doc in documents:\n",
    "    map_output.append(LLM(map_prompt(doc)))\n",
    "\n",
    "final_output = LLM(reduce_prompt(map_output))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Common Use Cases\n",
    "\n",
    "* Long document summarization\n",
    "* Meeting transcript summarization\n",
    "* Log analysis\n",
    "* Report aggregation\n",
    "* Multi-document RAG summarization\n",
    "\n",
    "---\n",
    "\n",
    "### MapReduce vs Stuff Chain\n",
    "\n",
    "| Aspect       | MapReduce       | Stuff        |\n",
    "| ------------ | --------------- | ------------ |\n",
    "| Scalability  | High            | Low          |\n",
    "| Context size | Small per chunk | Entire input |\n",
    "| Parallelism  | Yes             | No           |\n",
    "| Cost         | Higher          | Lower        |\n",
    "\n",
    "---\n",
    "\n",
    "### MapReduce vs Refine Chain\n",
    "\n",
    "| Aspect     | MapReduce        | Refine     |\n",
    "| ---------- | ---------------- | ---------- |\n",
    "| Processing | Parallel         | Sequential |\n",
    "| Latency    | Lower (parallel) | Higher     |\n",
    "| Accuracy   | Medium           | Higher     |\n",
    "\n",
    "---\n",
    "\n",
    "### Limitations of MapReduce Chain\n",
    "\n",
    "* ❌ More LLM calls (higher cost)\n",
    "* ❌ Loss of global context in map phase\n",
    "* ❌ Legacy abstraction\n",
    "* ❌ Less control than LCEL\n",
    "\n",
    "---\n",
    "\n",
    "### MapReduce Chain vs LCEL (Modern Approach)\n",
    "\n",
    "### Legacy MapReduce\n",
    "\n",
    "```python\n",
    "load_summarize_chain(chain_type=\"map_reduce\")\n",
    "```\n",
    "\n",
    "### LCEL Equivalent (Conceptual)\n",
    "\n",
    "```python\n",
    "chunks | map_chain | reduce_chain\n",
    "```\n",
    "\n",
    "LCEL allows:\n",
    "\n",
    "* Custom aggregation\n",
    "* Parallelism\n",
    "* Streaming\n",
    "* Better observability\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use MapReduce Chain\n",
    "\n",
    "* Very large documents\n",
    "* Summarization tasks\n",
    "* When context limits are hit\n",
    "* Legacy LangChain codebases\n",
    "\n",
    "---\n",
    "\n",
    "### When NOT to Use It\n",
    "\n",
    "* Small inputs\n",
    "* High-precision reasoning\n",
    "* Agent-based workflows\n",
    "* New projects (prefer LCEL)\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "* Use deterministic settings (temperature = 0)\n",
    "* Keep map outputs concise\n",
    "* Limit number of chunks\n",
    "* Validate reduce output\n",
    "* Monitor token usage\n",
    "\n",
    "---\n",
    "\n",
    "### Interview-Ready Summary\n",
    "\n",
    "> “A MapReduce Chain in LangChain processes large inputs by splitting them into chunks, summarizing or analyzing each chunk independently, and then combining the results. It enables scalable LLM processing but is a legacy abstraction superseded by LCEL.”\n",
    "\n",
    "---\n",
    "\n",
    "### Rule of Thumb\n",
    "\n",
    "* **Large documents → MapReduce**\n",
    "* **Small documents → Stuff**\n",
    "* **Incremental understanding → Refine**\n",
    "* **New systems → LCEL-based pipelines**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
