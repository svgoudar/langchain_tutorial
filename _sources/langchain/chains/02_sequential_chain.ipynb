{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ea4149",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## SequentialChain (LangChain)\n",
    "\n",
    "### What SequentialChain Is\n",
    "\n",
    "A **SequentialChain** is a **legacy LangChain construct** that allows you to **execute multiple chains one after another**, where the **output of one chain becomes the input of the next**.\n",
    "\n",
    "> SequentialChain models a **fixed, linear workflow** with multiple LLM calls.\n",
    "\n",
    "It was designed before **LCEL (Runnable-based pipelines)** existed.\n",
    "\n",
    "---\n",
    "\n",
    "### Why SequentialChain Exists\n",
    "\n",
    "SequentialChain was created to:\n",
    "\n",
    "* Break complex tasks into steps\n",
    "* Reuse intermediate outputs\n",
    "* Enforce execution order\n",
    "* Reduce prompt complexity per step\n",
    "\n",
    "Conceptually, it represents:\n",
    "\n",
    "```\n",
    "Chain A → Chain B → Chain C\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Core Concept\n",
    "\n",
    "Each chain:\n",
    "\n",
    "* Consumes input variables\n",
    "* Produces output variables\n",
    "* Passes outputs forward\n",
    "\n",
    "LangChain manages the **shared state dictionary**.\n",
    "\n",
    "---\n",
    "\n",
    "### Simple SequentialChain Example\n",
    "\n",
    "#### Step 1: Create Individual LLMChains\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25fab709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangouda\\AppData\\Local\\Temp\\ipykernel_42048\\829087398.py:17: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use `RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  title_chain = LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "title_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Generate a short title for {topic}\"\n",
    ")\n",
    "\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"title\"],\n",
    "    template=\"Write a 1-line summary for the title: {title}\"\n",
    ")\n",
    "\n",
    "title_chain = LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")\n",
    "summary_chain = LLMChain(llm=llm, prompt=summary_prompt, output_key=\"summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83f83c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Combine Using SequentialChain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8abd9d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains.sequential import SequentialChain\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[title_chain, summary_chain],\n",
    "    input_variables=[\"topic\"],\n",
    "    output_variables=[\"title\", \"summary\"],\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d68d93",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3: Invoke the Chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208aeab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'topic': 'LangChain', 'title': '\"LangChain: Empowering Language Models for Seamless Integration\"', 'summary': '\"LangChain enables effortless integration of language models into applications, enhancing their functionality and user experience.\"'}\n"
     ]
    }
   ],
   "source": [
    "result = overall_chain.invoke({\"topic\": \"LangChain\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d9bf6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"topic\": \"LangChain\",\n",
    "  \"title\": \"Building with Language Models\",\n",
    "  \"summary\": \"A concise overview of using language models in applications.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### How Data Flows Internally\n",
    "\n",
    "```\n",
    "Input: {\"topic\": \"LangChain\"}\n",
    "   ↓\n",
    "title_chain → {\"title\": \"...\"}\n",
    "   ↓\n",
    "summary_chain (uses title)\n",
    "   ↓\n",
    "Final Output\n",
    "```\n",
    "\n",
    "State is accumulated automatically.\n",
    "\n",
    "---\n",
    "\n",
    "### SimpleSequentialChain (Shortcut)\n",
    "\n",
    "#### When Only One Output Is Needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8cc5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains.sequential import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(\n",
    "    chains=[title_chain, summary_chain],\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f452584",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Limitations:\n",
    "\n",
    "* Single input\n",
    "* Single output\n",
    "* No variable control\n",
    "\n",
    "---\n",
    "\n",
    "### Common Use Cases\n",
    "\n",
    "* Stepwise text generation\n",
    "* Content pipelines\n",
    "* Summarization → rewriting\n",
    "* Classification → explanation\n",
    "* Translation → formatting\n",
    "\n",
    "---\n",
    "\n",
    "### Limitations of SequentialChain\n",
    "\n",
    "#### Structural Limitations\n",
    "\n",
    "* ❌ Linear only (no branching)\n",
    "* ❌ No parallelism\n",
    "* ❌ Weak streaming support\n",
    "* ❌ Poor async ergonomics\n",
    "* ❌ Legacy abstraction\n",
    "\n",
    "---\n",
    "\n",
    "### SequentialChain vs LCEL (Recommended)\n",
    "\n",
    "#### SequentialChain\n",
    "\n",
    "```python\n",
    "SequentialChain(chains=[a, b, c])\n",
    "```\n",
    "\n",
    "### LCEL Equivalent\n",
    "\n",
    "```python\n",
    "chain = a | b | c\n",
    "```\n",
    "\n",
    "LCEL:\n",
    "\n",
    "* Is Runnable-based\n",
    "* Supports streaming & async\n",
    "* Allows branching and parallelism\n",
    "* Is future-proof\n",
    "\n",
    "---\n",
    "\n",
    "### SequentialChain vs Agents\n",
    "\n",
    "| Aspect      | SequentialChain | Agent   |\n",
    "| ----------- | --------------- | ------- |\n",
    "| Flow        | Fixed           | Dynamic |\n",
    "| Tool usage  | ❌               | ✅       |\n",
    "| Reasoning   | ❌               | ✅       |\n",
    "| Determinism | High            | Lower   |\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use SequentialChain (Today)\n",
    "\n",
    "* Maintaining legacy code\n",
    "* Learning LangChain basics\n",
    "* Migrating step-by-step logic\n",
    "\n",
    "---\n",
    "\n",
    "### When NOT to Use SequentialChain\n",
    "\n",
    "* New projects\n",
    "* RAG pipelines\n",
    "* Agents\n",
    "* Production APIs\n",
    "* Streaming applications\n",
    "\n",
    "---\n",
    "\n",
    "### Migration Example (SequentialChain → LCEL)\n",
    "\n",
    "#### Before\n",
    "\n",
    "```python\n",
    "SequentialChain(chains=[chain1, chain2])\n",
    "```\n",
    "\n",
    "#### After\n",
    "\n",
    "```python\n",
    "chain = chain1 | chain2\n",
    "```\n",
    "\n",
    "Same logic, better execution model.\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices (If You Must Use It)\n",
    "\n",
    "* Keep chains small\n",
    "* Limit number of steps\n",
    "* Avoid complex variable graphs\n",
    "* Plan migration to LCEL\n",
    "\n",
    "---\n",
    "\n",
    "### Interview-Ready Summary\n",
    "\n",
    "> “SequentialChain is a legacy LangChain abstraction for executing multiple chains in a fixed order, passing outputs between them. It has largely been replaced by LCEL, which offers better composability, streaming, async support, and production readiness.”\n",
    "\n",
    "---\n",
    "\n",
    "### Rule of Thumb\n",
    "\n",
    "* **Linear legacy workflows → SequentialChain**\n",
    "* **Modern pipelines → LCEL**\n",
    "* **Dynamic reasoning → Agents or LangGraph**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f37bd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
