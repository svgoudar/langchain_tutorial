{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c42da3e",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## LangGraph Integration\n",
    "\n",
    "\n",
    "**LangGraph** is a framework built on top of LangChain that lets you build **stateful, multi-step, branching AI workflows** using a graph model.\n",
    "\n",
    "Instead of linear chains:\n",
    "\n",
    "```\n",
    "Prompt → LLM → Output\n",
    "```\n",
    "\n",
    "You build **graphs**:\n",
    "\n",
    "```\n",
    "Node → Decision → Branch → Node → Merge → Result\n",
    "```\n",
    "\n",
    "This enables:\n",
    "\n",
    "* Multi-agent systems\n",
    "* Tool orchestration\n",
    "* Feedback loops\n",
    "* Long-running stateful workflows\n",
    "\n",
    "---\n",
    "\n",
    "### Where LangGraph Fits\n",
    "\n",
    "```\n",
    "Client → FastAPI → LangGraph Workflow → LLM / Tools / DB → Result\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Basic LangGraph Graph Structure\n",
    "\n",
    "| Element | Purpose                      |\n",
    "| ------- | ---------------------------- |\n",
    "| State   | Shared memory across nodes   |\n",
    "| Node    | A step (LLM, tool, function) |\n",
    "| Edge    | Flow control                 |\n",
    "| Router  | Conditional branching        |\n",
    "\n",
    "---\n",
    "\n",
    "### Simple LangGraph Example\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    response = llm.invoke(state[\"question\"])\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"llm_step\", generate_answer)\n",
    "graph.set_entry_point(\"llm_step\")\n",
    "graph.set_finish_point(\"llm_step\")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "result = app.invoke({\"question\": \"Explain black holes\"})\n",
    "print(result[\"answer\"])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Conditional Routing Example\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "def router(state: State):\n",
    "    if \"math\" in state[\"question\"]:\n",
    "        return \"math_node\"\n",
    "    return \"general_node\"\n",
    "\n",
    "graph.add_node(\"math_node\", generate_answer)\n",
    "graph.add_node(\"general_node\", generate_answer)\n",
    "\n",
    "graph.add_conditional_edges(\"router\", router)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Multi-Step Workflow Example\n",
    "\n",
    "```python\n",
    "def summarize(state):\n",
    "    summary = llm.invoke(\"Summarize: \" + state[\"question\"])\n",
    "    return {\"answer\": summary.content}\n",
    "\n",
    "graph.add_node(\"summarize\", summarize)\n",
    "graph.add_edge(\"llm_step\", \"summarize\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Using LangGraph with FastAPI\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app_api = FastAPI()\n",
    "\n",
    "@app_api.post(\"/ask\")\n",
    "def ask(q: str):\n",
    "    return app.invoke({\"question\": q})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Why LangGraph Matters\n",
    "\n",
    "| Capability         | Benefit            |\n",
    "| ------------------ | ------------------ |\n",
    "| Stateful execution | Long conversations |\n",
    "| Branching          | Complex logic      |\n",
    "| Retry loops        | Reliability        |\n",
    "| Multi-agent        | Coordination       |\n",
    "\n",
    "---\n",
    "\n",
    "### Mental Model\n",
    "\n",
    "```\n",
    "LangGraph = Workflow engine for LLM intelligence\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* Moves beyond linear chains\n",
    "* Enables production-grade AI workflows\n",
    "* Supports agents, tools, memory, and feedback\n",
    "* Essential for complex LLM applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8497027",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
