{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327c88bd",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Logging\n",
    "\n",
    "\n",
    "**Logging** is the practice of **recording runtime events** (messages, errors, timings, states) so you can **debug, monitor, and audit** an application.\n",
    "\n",
    "In LLM systems, logging typically captures:\n",
    "\n",
    "* Inputs and outputs\n",
    "* Errors and exceptions\n",
    "* Latency and timing\n",
    "* Tool usage\n",
    "* Application state\n",
    "\n",
    "Logging is **developer-controlled** and **flat**, unlike tracing (which is hierarchical and automatic).\n",
    "\n",
    "---\n",
    "\n",
    "### Why Logging Is Important in LLM Systems\n",
    "\n",
    "Logging helps you answer:\n",
    "\n",
    "* *Did the request reach the model?*\n",
    "* *What input was sent?*\n",
    "* *What output was returned?*\n",
    "* *Did an error occur?*\n",
    "* *How long did it take?*\n",
    "\n",
    "It is essential for:\n",
    "\n",
    "* Debugging production issues\n",
    "* Compliance and audits\n",
    "* Incident investigation\n",
    "* Operational monitoring\n",
    "\n",
    "---\n",
    "\n",
    "### Logging vs Tracing (Quick Contrast)\n",
    "\n",
    "| Aspect    | Logging          | Tracing            |\n",
    "| --------- | ---------------- | ------------------ |\n",
    "| Structure | Flat text/events | Hierarchical       |\n",
    "| Control   | Manual           | Automatic          |\n",
    "| Scope     | App-level        | Execution-level    |\n",
    "| Storage   | Files / stdout   | Tracing backend    |\n",
    "| Use case  | Debug & audit    | Deep observability |\n",
    "\n",
    "Both are **complementary**, not competing.\n",
    "\n",
    "---\n",
    "\n",
    "### Basic Logging in Python (Foundation)\n",
    "\n",
    "```python\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "\n",
    "logging.info(\"Application started\")\n",
    "logging.warning(\"This is a warning\")\n",
    "logging.error(\"Something went wrong\")\n",
    "```\n",
    "\n",
    "This sets up:\n",
    "\n",
    "* Log level\n",
    "* Timestamped output\n",
    "* Console logging\n",
    "\n",
    "---\n",
    "\n",
    "### Logging in an LLM Pipeline (LangChain Example)\n",
    "\n",
    "Using LangChain.\n",
    "\n",
    "```python\n",
    "import logging\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "def ask_llm(question: str):\n",
    "    logger.info(\"LLM request received: %s\", question)\n",
    "\n",
    "    response = llm.invoke(question)\n",
    "\n",
    "    logger.info(\"LLM response length: %d\", len(response.content))\n",
    "    return response.content\n",
    "```\n",
    "\n",
    "What gets logged:\n",
    "\n",
    "* User input\n",
    "* Response metadata (not full text, safer)\n",
    "* Execution flow\n",
    "\n",
    "---\n",
    "\n",
    "### Logging Errors and Exceptions\n",
    "\n",
    "```python\n",
    "try:\n",
    "    result = ask_llm(\"Explain logging\")\n",
    "except Exception as e:\n",
    "    logging.exception(\"LLM call failed\")\n",
    "```\n",
    "\n",
    "`logging.exception()` automatically logs:\n",
    "\n",
    "* Error message\n",
    "* Full stack trace\n",
    "\n",
    "---\n",
    "\n",
    "### Logging Inside Runnable Chains\n",
    "\n",
    "```python\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def log_input(x):\n",
    "    logging.info(\"Runnable input: %s\", x)\n",
    "    return x\n",
    "\n",
    "chain = (\n",
    "    RunnableLambda(log_input)\n",
    "    | RunnableLambda(lambda x: x.upper())\n",
    ")\n",
    "```\n",
    "\n",
    "Each runnable can log:\n",
    "\n",
    "* Inputs\n",
    "* Outputs\n",
    "* Decisions\n",
    "\n",
    "---\n",
    "\n",
    "### Logging with Callback Handlers (Advanced Pattern)\n",
    "\n",
    "```python\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "import logging\n",
    "\n",
    "class LoggingCallback(BaseCallbackHandler):\n",
    "    def on_chain_start(self, serialized, inputs, **kwargs):\n",
    "        logging.info(\"Chain started with inputs: %s\", inputs)\n",
    "\n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        logging.info(\"LLM finished\")\n",
    "\n",
    "llm = ChatOpenAI(callbacks=[LoggingCallback()])\n",
    "llm.invoke(\"Explain logging\")\n",
    "```\n",
    "\n",
    "This logs **internal execution events**.\n",
    "\n",
    "---\n",
    "\n",
    "### Logging in FastAPI (Real-World)\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "import logging\n",
    "\n",
    "app = FastAPI()\n",
    "logger = logging.getLogger(\"api\")\n",
    "\n",
    "@app.get(\"/chat\")\n",
    "async def chat(q: str):\n",
    "    logger.info(\"Incoming query: %s\", q)\n",
    "    return {\"answer\": q.upper()}\n",
    "```\n",
    "\n",
    "Typical production flow:\n",
    "\n",
    "* Request received\n",
    "* Processing steps logged\n",
    "* Response returned\n",
    "\n",
    "---\n",
    "\n",
    "### Log Levels (Use Correctly)\n",
    "\n",
    "| Level    | Use                    |\n",
    "| -------- | ---------------------- |\n",
    "| DEBUG    | Detailed dev info      |\n",
    "| INFO     | Normal operations      |\n",
    "| WARNING  | Unexpected but handled |\n",
    "| ERROR    | Failed operation       |\n",
    "| CRITICAL | App may crash          |\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "logging.debug(\"Prompt template rendered\")\n",
    "logging.info(\"LLM call successful\")\n",
    "logging.error(\"Timeout calling model\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### What NOT to Log\n",
    "\n",
    "Avoid logging:\n",
    "\n",
    "* API keys\n",
    "* Tokens\n",
    "* PII (emails, phone numbers)\n",
    "* Full prompts/responses in prod\n",
    "\n",
    "Safe pattern:\n",
    "\n",
    "```python\n",
    "logging.info(\"LLM called, tokens=%d\", token_count)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Logging to Files (Production)\n",
    "\n",
    "```python\n",
    "logging.basicConfig(\n",
    "    filename=\"app.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\"\n",
    ")\n",
    "```\n",
    "\n",
    "Often combined with:\n",
    "\n",
    "* Log rotation\n",
    "* Centralized log collectors (ELK, CloudWatch)\n",
    "\n",
    "---\n",
    "\n",
    "### Common Logging Mistakes\n",
    "\n",
    "* Logging too much (noise)\n",
    "* Logging secrets\n",
    "* Using `print()` instead of logging\n",
    "* No log levels\n",
    "* No timestamps\n",
    "\n",
    "---\n",
    "\n",
    "### Mental Model\n",
    "\n",
    "Logging is your **black box recorder**:\n",
    "\n",
    "```\n",
    "Event happens → log entry written → stored for later inspection\n",
    "```\n",
    "\n",
    "Tracing tells *how execution flowed*\n",
    "Logging tells *what happened at key points*\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* Logging records **application events**\n",
    "* Manual and developer-controlled\n",
    "* Essential for debugging and audits\n",
    "* Complements tracing and callbacks\n",
    "* Must be secure and level-based\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
