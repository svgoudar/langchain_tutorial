{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1852a59d",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Background Tasks\n",
    "\n",
    "\n",
    "**Background tasks** are operations that run **asynchronously** after an API request is returned to the user, without blocking the main request–response cycle.\n",
    "\n",
    "They are used for:\n",
    "\n",
    "* Logging\n",
    "* Sending emails / notifications\n",
    "* Data processing\n",
    "* Model training / indexing\n",
    "* Long-running LLM jobs\n",
    "\n",
    "---\n",
    "\n",
    "### Why Background Tasks Are Needed\n",
    "\n",
    "Without background tasks:\n",
    "\n",
    "```\n",
    "Client waits → Server blocks → Timeouts → Poor UX\n",
    "```\n",
    "\n",
    "With background tasks:\n",
    "\n",
    "```\n",
    "Client gets response immediately → Task runs in background\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Where They Fit in the System\n",
    "\n",
    "```\n",
    "Client Request\n",
    "     ↓\n",
    "API Handler → Return Response Immediately\n",
    "     ↓\n",
    "Background Task Executes Independently\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### FastAPI Background Tasks (Native Support)\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI, BackgroundTasks\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "def write_log(message: str):\n",
    "    with open(\"log.txt\", \"a\") as f:\n",
    "        f.write(message + \"\\n\")\n",
    "\n",
    "@app.post(\"/process\")\n",
    "def process_task(data: str, background_tasks: BackgroundTasks):\n",
    "    background_tasks.add_task(write_log, f\"Processed: {data}\")\n",
    "    return {\"status\": \"Task started\"}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Long-Running Task Example\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "import time\n",
    "\n",
    "def long_job(job_id):\n",
    "    time.sleep(10)\n",
    "    print(f\"Job {job_id} completed\")\n",
    "\n",
    "@app.post(\"/start-job\")\n",
    "def start_job(job_id: int, background_tasks: BackgroundTasks):\n",
    "    background_tasks.add_task(long_job, job_id)\n",
    "    return {\"message\": \"Job running in background\"}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Background Tasks with LLM Work\n",
    "\n",
    "```python\n",
    "def generate_embeddings(text):\n",
    "    vector = embedding_model.encode(text)\n",
    "    store_vector(vector)\n",
    "\n",
    "@app.post(\"/upload\")\n",
    "def upload(text: str, background_tasks: BackgroundTasks):\n",
    "    background_tasks.add_task(generate_embeddings, text)\n",
    "    return {\"status\": \"Indexing started\"}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use External Workers\n",
    "\n",
    "FastAPI background tasks are **in-process**.\n",
    "For heavy or critical workloads use **Celery / RQ / Dramatiq**.\n",
    "\n",
    "#### Example with Celery\n",
    "\n",
    "```python\n",
    "@celery.task\n",
    "def process_large_file(file_id):\n",
    "    ...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Reliability Considerations\n",
    "\n",
    "| Concern        | Solution            |\n",
    "| -------------- | ------------------- |\n",
    "| Task crash     | Retry logic         |\n",
    "| Server restart | External queue      |\n",
    "| High load      | Distributed workers |\n",
    "| Tracking       | Job status store    |\n",
    "\n",
    "---\n",
    "\n",
    "### Mental Model\n",
    "\n",
    "```\n",
    "Background Tasks = Work done after the user has already been answered\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* Improves responsiveness dramatically\n",
    "* Essential for production APIs\n",
    "* FastAPI provides built-in support\n",
    "* Use task queues for heavy workloads"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
