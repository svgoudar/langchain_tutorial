{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcea1747",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Gradio and Streamlit UI\n",
    "\n",
    "\n",
    "**Gradio** and **Streamlit** provide the **user interaction layer** for LLM applications.\n",
    "They allow users to submit prompts, view responses, upload files, and interact with AI systems visually without building frontend code.\n",
    "\n",
    "**Architecture Position**\n",
    "\n",
    "```\n",
    "User → Gradio / Streamlit UI → Backend API / LangChain → LLM → UI → User\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Gradio — Concept & Use Case\n",
    "\n",
    "**Gradio** is designed for:\n",
    "\n",
    "* Rapid prototyping\n",
    "* ML demos\n",
    "* Model testing\n",
    "* Internal tools\n",
    "\n",
    "Minimal code, very fast setup.\n",
    "\n",
    "---\n",
    "\n",
    "### Gradio Demonstration\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "def chat(prompt):\n",
    "    return llm.invoke(prompt).content\n",
    "\n",
    "app = gr.Interface(\n",
    "    fn=chat,\n",
    "    inputs=gr.Textbox(lines=4, placeholder=\"Ask something...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"LLM Chat\"\n",
    ")\n",
    "\n",
    "app.launch()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Streamlit — Concept & Use Case\n",
    "\n",
    "**Streamlit** is used for:\n",
    "\n",
    "* Dashboards\n",
    "* Analytics\n",
    "* Full AI products\n",
    "* Internal enterprise apps\n",
    "\n",
    "Supports layouts, state, charts, uploads, and session control.\n",
    "\n",
    "---\n",
    "\n",
    "### Streamlit Demonstration\n",
    "\n",
    "```python\n",
    "import streamlit as st\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "st.title(\"LLM Assistant\")\n",
    "\n",
    "prompt = st.text_area(\"Enter your question\")\n",
    "\n",
    "if st.button(\"Submit\"):\n",
    "    answer = llm.invoke(prompt).content\n",
    "    st.write(answer)\n",
    "```\n",
    "\n",
    "Run:\n",
    "\n",
    "```bash\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Advanced: RAG UI Example (Streamlit)\n",
    "\n",
    "```python\n",
    "uploaded_file = st.file_uploader(\"Upload document\")\n",
    "\n",
    "if uploaded_file:\n",
    "    text = uploaded_file.read().decode()\n",
    "    retriever.add_texts([text])\n",
    "\n",
    "query = st.text_input(\"Ask about your document\")\n",
    "\n",
    "if st.button(\"Ask\"):\n",
    "    response = rag_chain.invoke({\"query\": query})[\"result\"]\n",
    "    st.write(response)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Gradio vs Streamlit Comparison\n",
    "\n",
    "| Feature        | Gradio    | Streamlit |\n",
    "| -------------- | --------- | --------- |\n",
    "| Setup speed    | Very fast | Fast      |\n",
    "| UI flexibility | Basic     | Rich      |\n",
    "| State handling | Limited   | Strong    |\n",
    "| Best for       | Demos     | Products  |\n",
    "| Customization  | Low       | High      |\n",
    "\n",
    "---\n",
    "\n",
    "### Mental Model\n",
    "\n",
    "```\n",
    "Gradio = Demo UI\n",
    "Streamlit = Application UI\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* Both provide zero-frontend AI interfaces\n",
    "* Gradio excels at quick experiments\n",
    "* Streamlit excels at full AI applications\n",
    "* Both integrate seamlessly with LangChain and FastAPI\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
