{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fbc2256",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Agent Memory\n",
    "\n",
    "\n",
    "**Agent memory** is the mechanism that lets an agent **persist and reuse state across turns or steps**, enabling coherent, stateful behavior instead of stateless, one-off responses.\n",
    "\n",
    "> Memory answers: *“What should the agent remember from the past to act better now?”*\n",
    "\n",
    "---\n",
    "\n",
    "### What Agent Memory Is NOT\n",
    "\n",
    "* ❌ Not the model’s training data\n",
    "* ❌ Not `agent_scratchpad` (which is per-run reasoning)\n",
    "* ❌ Not permanent world knowledge by default\n",
    "\n",
    "Memory is **runtime state**, scoped to a **session, conversation, or workflow**.\n",
    "\n",
    "---\n",
    "\n",
    "### Where Agent Memory Fits\n",
    "\n",
    "```\n",
    "User Input\n",
    "   ↓\n",
    "Memory (read)\n",
    "   ↓\n",
    "Agent Reasoning / Tool Use / Retrieval\n",
    "   ↓\n",
    "Response\n",
    "   ↓\n",
    "Memory (write/update)\n",
    "```\n",
    "\n",
    "Memory is **read before reasoning** and **updated after each turn**.\n",
    "\n",
    "---\n",
    "\n",
    "### Agent Memory vs agent_scratchpad\n",
    "\n",
    "| Aspect       | Agent Memory             | agent_scratchpad              |\n",
    "| ------------ | ------------------------ | ----------------------------- |\n",
    "| Purpose      | Remembering across turns | Reasoning within a single run |\n",
    "| Scope        | Multi-turn/session       | Single execution              |\n",
    "| Persistence  | Yes (session)            | No                            |\n",
    "| User-visible | Indirect                 | No                            |\n",
    "\n",
    "They solve **different problems** and are often used together.\n",
    "\n",
    "---\n",
    "\n",
    "### Core Types of Agent Memory\n",
    "\n",
    "#### 1) Conversation Buffer Memory\n",
    "\n",
    "Stores the **entire conversation history**.\n",
    "\n",
    "* **Pros:** Simple, faithful recall\n",
    "* **Cons:** Grows unbounded; token pressure\n",
    "\n",
    "**Use when:** Short conversations, low token risk.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2) Conversation Window Memory\n",
    "\n",
    "Keeps **only the last N turns**.\n",
    "\n",
    "* **Pros:** Predictable size\n",
    "* **Cons:** Older context lost\n",
    "\n",
    "**Use when:** Only recent context matters.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3) Conversation Summary Memory\n",
    "\n",
    "Summarizes older turns into a **compact abstract**.\n",
    "\n",
    "* **Pros:** Scales to long chats\n",
    "* **Cons:** Possible summary drift\n",
    "\n",
    "**Use when:** Long-running conversations.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4) Hybrid (Summary + Window) Memory\n",
    "\n",
    "Recent turns + summarized past.\n",
    "\n",
    "* **Pros:** Best balance (production standard)\n",
    "* **Cons:** Slight complexity\n",
    "\n",
    "**Use when:** Enterprise chatbots and assistants.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5) Entity Memory\n",
    "\n",
    "Tracks **entities and attributes** (names, IDs, preferences).\n",
    "\n",
    "* **Pros:** Structured recall of facts\n",
    "* **Cons:** Needs clean extraction\n",
    "\n",
    "**Use when:** CRM/support agents with identifiers.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6) Vector (Long-Term) Memory\n",
    "\n",
    "Stores past interactions as **embeddings** for semantic recall.\n",
    "\n",
    "* **Pros:** Long-term personalization\n",
    "* **Cons:** Retrieval tuning required\n",
    "\n",
    "**Use when:** Personalized assistants over time.\n",
    "\n",
    "---\n",
    "\n",
    "### Agent Memory vs RAG\n",
    "\n",
    "| Dimension | Memory             | RAG                |\n",
    "| --------- | ------------------ | ------------------ |\n",
    "| Purpose   | Conversation state | External knowledge |\n",
    "| Source    | User interactions  | Documents/DBs      |\n",
    "| Update    | Every turn         | Ingestion-time     |\n",
    "| Scope     | Session/user       | Global/shared      |\n",
    "\n",
    "They are **complementary**: memory for *context*, RAG for *facts*.\n",
    "\n",
    "---\n",
    "\n",
    "### How Memory Is Injected\n",
    "\n",
    "Agents typically build prompts like:\n",
    "\n",
    "```\n",
    "System Instructions\n",
    "+ Memory (formatted)\n",
    "+ User Input\n",
    "+ agent_scratchpad\n",
    "```\n",
    "\n",
    "Memory influences **intent resolution**, **follow-ups**, and **tool decisions**.\n",
    "\n",
    "---\n",
    "\n",
    "### Memory in Agents (Execution)\n",
    "\n",
    "When running an agent:\n",
    "\n",
    "* **Read:** Memory is loaded before reasoning\n",
    "* **Write:** New turns (or summaries) are appended after the response\n",
    "\n",
    "This happens automatically when memory is attached to the executor.\n",
    "\n",
    "---\n",
    "\n",
    "### Production Concerns\n",
    "\n",
    "#### Context Window Management\n",
    "\n",
    "* Memory consumes tokens\n",
    "* Use windows, summaries, or compression\n",
    "\n",
    "#### Safety & Privacy\n",
    "\n",
    "* Memory may include PII\n",
    "* Enforce retention and deletion policies\n",
    "\n",
    "#### Accuracy Drift\n",
    "\n",
    "* Summaries can accumulate errors\n",
    "* Validate what gets written to memory\n",
    "\n",
    "---\n",
    "\n",
    "### Common Mistakes\n",
    "\n",
    "* Using full buffer memory indefinitely → token overflow\n",
    "* Confusing memory with scratchpad → logic errors\n",
    "* Storing hallucinations → compounding mistakes\n",
    "* Sharing memory across users → data leakage\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "* Prefer **hybrid memory** (summary + window)\n",
    "* Clear memory per session/user\n",
    "* Don’t store tool internals unless needed\n",
    "* Validate memory updates\n",
    "* Monitor token usage\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use Agent Memory\n",
    "\n",
    "* Conversational agents\n",
    "* Multi-step workflows\n",
    "* Personalization\n",
    "* Long-running sessions\n",
    "\n",
    "---\n",
    "\n",
    "### When NOT to Use It\n",
    "\n",
    "* Single-turn APIs\n",
    "* Stateless services\n",
    "* High-throughput endpoints\n",
    "\n",
    "---\n",
    "\n",
    "### Interview-Ready Summary\n",
    "\n",
    "> “Agent memory enables stateful behavior by persisting conversational context across turns. It is distinct from the agent scratchpad and from RAG, and must be managed carefully to balance recall, cost, and safety.”\n",
    "\n",
    "---\n",
    "\n",
    "### Rule of Thumb\n",
    "\n",
    "* **Scratchpad → thinking**\n",
    "* **Memory → remembering**\n",
    "* **RAG → knowing**\n",
    "* **LLM → reasoning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d9c451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, Sanjeev! How can I assist you today?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke({\"input\": \"My name is Sanjeev\"}).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a79fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about you unless you share it with me. How can I assist you today?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What is my name?\"}).content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f1324",
   "metadata": {},
   "source": [
    "Why This Happens\n",
    "\n",
    "No memory\n",
    "\n",
    "Each call is independent\n",
    "\n",
    "The model has no past context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc8b8605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sangouda\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangouda\\AppData\\Local\\Temp\\ipykernel_39492\\2940709401.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from langchain_classic.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0f374e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Agent with memory\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from langchain_classic.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\"  # Explicitly set the key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "648fcf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"placeholder\", \"{chat_history}\"),  # This injects the memory!\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")  # Separate placeholder for scratchpad\n",
    "])\n",
    "\n",
    "agent = create_openai_tools_agent(\n",
    "    llm=llm,\n",
    "    tools=[],  # no tools needed for this demo\n",
    "    prompt=prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e51bf153",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=[],\n",
    "    memory=memory,\n",
    "    # verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "066324a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=[],\n",
    "    memory=memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98ddb382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello again, Sanjeev! How can I help you today?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Stateful Conversation with an Agent\n",
    "answer = executor.invoke({\"input\": \"My name is Sanjeev\"})\n",
    "answer['output']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d819a",
   "metadata": {},
   "source": [
    "**Memory now contains the conversation history**\n",
    "- Human: My name is Sanjeev\n",
    "- AI: Nice to meet you, Sanjeev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fba7b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Sanjeev.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = executor.invoke({\"input\": \"What is my name?\"})\n",
    "answer['output']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378dfeff",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
