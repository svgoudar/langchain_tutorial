{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0a2ce1",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Faithfulness\n",
    "\n",
    "\n",
    "**Faithfulness** measures whether an LLM’s answer is **strictly grounded in the provided context** and **does not introduce unsupported facts** (hallucinations).\n",
    "\n",
    "In RAG systems, faithfulness answers one critical question:\n",
    "\n",
    "> **Is every claim in the answer supported by the retrieved documents?**\n",
    "\n",
    "Faithfulness is a **core evaluation dimension** in LangChain and RAG systems.\n",
    "\n",
    "```\n",
    "Context (Sources)\n",
    "   ↓\n",
    "LLM Answer\n",
    "   ↓\n",
    "Faithfulness Check\n",
    "   → Supported ✅\n",
    "   → Unsupported ❌ (Hallucination)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Why Faithfulness Is Critical\n",
    "\n",
    "An answer can be:\n",
    "\n",
    "* Fluent ❌\n",
    "* Confident ❌\n",
    "* Wrong ❌\n",
    "\n",
    "Faithfulness ensures:\n",
    "\n",
    "* No hallucinated facts\n",
    "* Trustworthy answers\n",
    "* Explainability via sources\n",
    "* Production safety\n",
    "\n",
    "This is **more important than fluency** in enterprise RAG.\n",
    "\n",
    "---\n",
    "\n",
    "### Faithfulness vs Correctness\n",
    "\n",
    "| Dimension              | Faithfulness | Correctness |\n",
    "| ---------------------- | ------------ | ----------- |\n",
    "| Depends on context     | ✅            | ❌           |\n",
    "| Detects hallucinations | ✅            | ❌           |\n",
    "| Checks factual truth   | ❌            | ✅           |\n",
    "| RAG-specific           | ✅            | ❌           |\n",
    "\n",
    "An answer can be **correct but unfaithful** if it uses outside knowledge.\n",
    "\n",
    "---\n",
    "\n",
    "### Architecture View\n",
    "\n",
    "![Image](https://miro.medium.com/v2/resize%3Afit%3A1400/0%2A0VW2uHaAq2dB_AuH.png)\n",
    "\n",
    "![Image](https://substackcdn.com/image/fetch/%24s_%21mGi3%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a1c4ac0-aa62-40a6-8c6d-446756abee60_1400x1018.png)\n",
    "\n",
    "![Image](https://miro.medium.com/v2/resize%3Afit%3A1208/0%2AgJeMETTHMmgG2siR.png)\n",
    "\n",
    "---\n",
    "\n",
    "### Example Context and Question\n",
    "\n",
    "#### Retrieved Context\n",
    "\n",
    "```text\n",
    "RAG (Retrieval-Augmented Generation) combines document retrieval\n",
    "with language model generation to answer user questions.\n",
    "```\n",
    "\n",
    "#### Question\n",
    "\n",
    "```text\n",
    "What is RAG?\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Faithful vs Unfaithful Answers\n",
    "\n",
    "#### Faithful Answer ✅\n",
    "\n",
    "```text\n",
    "RAG combines document retrieval with language model generation.\n",
    "```\n",
    "\n",
    "✔ Every statement appears in the context.\n",
    "\n",
    "---\n",
    "\n",
    "#### Unfaithful Answer ❌\n",
    "\n",
    "```text\n",
    "RAG retrieves documents and fine-tunes the model in real time.\n",
    "```\n",
    "\n",
    "❌ “fine-tunes the model” is **not present** in the context → hallucination.\n",
    "\n",
    "---\n",
    "\n",
    "### Faithfulness Evaluation Using LangChain\n",
    "\n",
    "#### Load the Faithfulness Evaluator\n",
    "\n",
    "```python\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "faithfulness_eval = load_evaluator(\"faithfulness\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Evaluate a Faithful Answer\n",
    "\n",
    "```python\n",
    "result = faithfulness_eval.evaluate_strings(\n",
    "    input=\"What is RAG?\",\n",
    "    prediction=\"RAG combines document retrieval with language model generation.\",\n",
    "    reference=\"RAG combines document retrieval with language model generation.\"\n",
    ")\n",
    "\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output (example)**\n",
    "\n",
    "```python\n",
    "{\"score\": 1.0, \"reasoning\": \"All claims are supported by the context.\"}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Evaluate an Unfaithful Answer\n",
    "\n",
    "```python\n",
    "result = faithfulness_eval.evaluate_strings(\n",
    "    input=\"What is RAG?\",\n",
    "    prediction=\"RAG retrieves documents and fine-tunes models in real time.\",\n",
    "    reference=\"RAG combines document retrieval with language model generation.\"\n",
    ")\n",
    "\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output (example)**\n",
    "\n",
    "```python\n",
    "{\"score\": 0.0, \"reasoning\": \"The answer includes unsupported claims.\"}\n",
    "```\n",
    "\n",
    "This flags **hallucination**.\n",
    "\n",
    "---\n",
    "\n",
    "### Faithfulness in a Real RAG Pipeline\n",
    "\n",
    "#### RAG Output + Retrieved Docs\n",
    "\n",
    "```python\n",
    "answer = response.content\n",
    "context = \"\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Faithfulness Check on RAG Output\n",
    "\n",
    "```python\n",
    "faithfulness_eval.evaluate_strings(\n",
    "    input=question,\n",
    "    prediction=answer,\n",
    "    reference=context\n",
    ")\n",
    "```\n",
    "\n",
    "This is how **production RAG systems validate grounding**.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpreting Faithfulness Scores\n",
    "\n",
    "| Score | Meaning            |\n",
    "| ----- | ------------------ |\n",
    "| 1.0   | Fully grounded     |\n",
    "| 0.5   | Partially grounded |\n",
    "| 0.0   | Hallucinated       |\n",
    "\n",
    "Thresholds are usually:\n",
    "\n",
    "* **≥ 0.8 → Accept**\n",
    "* **< 0.8 → Reject / regenerate**\n",
    "\n",
    "---\n",
    "\n",
    "### Common Faithfulness Failure Patterns\n",
    "\n",
    "| Pattern             | Example                   |\n",
    "| ------------------- | ------------------------- |\n",
    "| Added facts         | “fine-tuned in real time” |\n",
    "| External knowledge  | Info not in docs          |\n",
    "| Over-generalization | Claims beyond context     |\n",
    "| Assumptions         | “typically”, “usually”    |\n",
    "\n",
    "---\n",
    "\n",
    "### Faithfulness vs Safety\n",
    "\n",
    "Faithfulness protects against:\n",
    "\n",
    "* Misinformation\n",
    "* Legal risk\n",
    "* Medical / financial hallucinations\n",
    "\n",
    "It is a **precondition for safety**, not a replacement.\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices to Improve Faithfulness\n",
    "\n",
    "* Use strict prompts:\n",
    "\n",
    "  > “Answer using **only** the provided context”\n",
    "* Reduce context size\n",
    "* Improve retrieval precision\n",
    "* Use citations\n",
    "* Reject low-faithfulness outputs\n",
    "\n",
    "---\n",
    "\n",
    "### Mental Model\n",
    "\n",
    "Faithfulness is a **contract**:\n",
    "\n",
    "> *If it’s not in the context, it must not be in the answer.*\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* Faithfulness checks **groundedness**, not truth\n",
    "* Core metric for RAG evaluation\n",
    "* Detects hallucinations reliably\n",
    "* More important than fluency\n",
    "* Mandatory for production RAG systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d364b7d6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
