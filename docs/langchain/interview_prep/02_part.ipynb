{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ecd508",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "## 1.1 Core Understanding\n",
    "\n",
    "### 1. What is Generative AI?\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "**Generative AI** is a class of artificial intelligence systems that **create new content** such as text, images, audio, video, or code by learning patterns from large datasets and then producing novel outputs that resemble the learned data.\n",
    "\n",
    "**Example:**\n",
    "ChatGPT generating text, DALL·E generating images, Copilot generating code.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 2. What is an LLM and how does it differ from traditional ML models?\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "An **LLM (Large Language Model)** is a deep neural network (usually Transformer-based) trained on massive text corpora to understand and generate human language.\n",
    "\n",
    "| Traditional ML         | LLM                                  |\n",
    "| ---------------------- | ------------------------------------ |\n",
    "| Task-specific          | General-purpose language system      |\n",
    "| Feature-engineered     | Learns representations automatically |\n",
    "| Small datasets         | Trained on internet-scale data       |\n",
    "| Fixed output structure | Flexible, generative output          |\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 3. What are the key components of a GenAI application?\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "A typical GenAI system includes:\n",
    "\n",
    "1. **User Interface** – Web/app frontend\n",
    "2. **Orchestration Layer** – LangChain, custom pipelines\n",
    "3. **Prompt Management** – Templates, versions\n",
    "4. **Model Layer** – LLMs (GPT, Claude, LLaMA, etc.)\n",
    "5. **Retrieval System** – Vector DB + embeddings\n",
    "6. **Data Sources** – Documents, databases, APIs\n",
    "7. **Memory & State** – Conversation & session data\n",
    "8. **Monitoring & Evaluation** – Logs, metrics, feedback\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 4. What is prompt engineering?\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "**Prompt engineering** is the practice of designing and structuring input instructions so the LLM produces accurate, consistent, and useful outputs.\n",
    "\n",
    "Includes:\n",
    "\n",
    "* Role definition\n",
    "* Output formatting\n",
    "* Constraints\n",
    "* Examples (few-shot learning)\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 5. What is temperature and top-p sampling?\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "Both control randomness in output generation.\n",
    "\n",
    "| Parameter   | Purpose                                                  |\n",
    "| ----------- | -------------------------------------------------------- |\n",
    "| Temperature | Controls creativity (0 = deterministic, high = creative) |\n",
    "| Top-p       | Limits token choices to most probable cumulative mass    |\n",
    "\n",
    "Used to balance **accuracy vs creativity**.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 6. What is context window?\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "The **context window** is the maximum number of tokens a model can read and generate in a single request.\n",
    "\n",
    "Includes:\n",
    "\n",
    "* Prompt\n",
    "* Retrieved documents\n",
    "* Conversation history\n",
    "* Model response\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 7. What is tokenization?\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "**Tokenization** is breaking text into smaller units (tokens) the model understands.\n",
    "\n",
    "Example:\n",
    "\"Artificial Intelligence\" → [\"Artificial\", \"Intelligence\"]\n",
    "\n",
    "Models operate on tokens, not raw text.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 8. What is inference vs training?\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "| Training           | Inference           |\n",
    "| ------------------ | ------------------- |\n",
    "| Learning from data | Using trained model |\n",
    "| Compute-heavy      | Latency-sensitive   |\n",
    "| Offline process    | Real-time process   |\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 9. What is hallucination in LLMs?\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "A **hallucination** occurs when an LLM generates information that is **factually incorrect or unsupported**, while sounding confident.\n",
    "\n",
    "Mitigated using:\n",
    "\n",
    "* Retrieval (RAG)\n",
    "* Verification steps\n",
    "* Strict prompting\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Why are embeddings important?\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "**Embeddings** convert text into numeric vectors representing meaning.\n",
    "\n",
    "They enable:\n",
    "\n",
    "* Semantic search\n",
    "* Document retrieval\n",
    "* Clustering\n",
    "* Recommendation systems\n",
    "\n",
    "Core to modern RAG systems.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2 Simple Design Scenarios\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Design a Chatbot for FAQs\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "1. User query\n",
    "2. Embed query\n",
    "3. Retrieve relevant FAQs from vector DB\n",
    "4. Inject into prompt\n",
    "5. LLM generates answer\n",
    "6. Return response\n",
    "\n",
    "**Key concerns:** latency, accuracy, fallback responses\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Design a Document Summarization System\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "**Flow:**\n",
    "\n",
    "1. Upload document\n",
    "2. Chunk text\n",
    "3. Summarize each chunk\n",
    "4. Combine summaries\n",
    "5. Generate final summary\n",
    "\n",
    "Handles long documents using chunking + hierarchical summarization.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Design a Resume Screening System\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "**Pipeline:**\n",
    "\n",
    "1. Upload resumes\n",
    "2. Extract text\n",
    "3. Generate embeddings\n",
    "4. Compare with job description embedding\n",
    "5. Rank candidates\n",
    "6. Generate evaluation summary\n",
    "\n",
    "Supports objective, scalable hiring decisions.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Design a Content Generation Pipeline\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "**Flow:**\n",
    "\n",
    "1. Input: topic + constraints\n",
    "2. Prompt template selection\n",
    "3. LLM generation\n",
    "4. Quality checks\n",
    "5. Human approval (optional)\n",
    "6. Publish\n",
    "\n",
    "Includes moderation, versioning, and feedback loop.\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d073b7",
   "metadata": {},
   "source": [
    "### 1. Explain Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "RAG combines **search** and **generation**.\n",
    "Instead of relying only on the LLM’s training data, the system retrieves relevant external knowledge and provides it to the model before generating a response.\n",
    "\n",
    "**Pipeline:**\n",
    "User Query → Embedding → Vector Search → Relevant Documents → Prompt Construction → LLM → Answer\n",
    "\n",
    "**Why it matters:**\n",
    "Higher accuracy, up-to-date knowledge, lower hallucination.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Design a GenAI-Powered Enterprise Search Engine\n",
    "\n",
    "**Components:**\n",
    "\n",
    "1. **Ingestion:** Documents, databases, APIs\n",
    "2. **Preprocessing:** Cleaning, chunking\n",
    "3. **Embedding:** Convert chunks to vectors\n",
    "4. **Storage:** Vector database + metadata store\n",
    "5. **Query Handling:**\n",
    "   Query → embed → retrieve top-k chunks\n",
    "6. **Generation:** LLM answers using retrieved content\n",
    "7. **Output:** Ranked results with citations\n",
    "\n",
    "**Key Features:**\n",
    "Access control, logging, feedback loop, caching.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. How Do Vector Databases Work Internally?\n",
    "\n",
    "1. Store high-dimensional vectors\n",
    "2. Build indexes (HNSW, IVF, PQ) for fast search\n",
    "3. Perform **Approximate Nearest Neighbor** search\n",
    "4. Return closest vectors by similarity (cosine, dot-product)\n",
    "5. Attach metadata for filtering\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Compare Fine-Tuning vs RAG\n",
    "\n",
    "| Fine-Tuning           | RAG               |\n",
    "| --------------------- | ----------------- |\n",
    "| Model weights updated | Model unchanged   |\n",
    "| Slow & expensive      | Fast & flexible   |\n",
    "| Static knowledge      | Dynamic knowledge |\n",
    "| Hard to maintain      | Easy to update    |\n",
    "\n",
    "---\n",
    "\n",
    "### 5. How Do You Build a Conversational Memory System?\n",
    "\n",
    "1. Store conversation history\n",
    "2. Summarize older interactions\n",
    "3. Convert memory into embeddings\n",
    "4. Retrieve relevant memory per query\n",
    "5. Inject into prompt dynamically\n",
    "\n",
    "Supports both short-term and long-term memory.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Handling Long Documents Beyond Context Limits\n",
    "\n",
    "* Chunk documents\n",
    "* Create embeddings\n",
    "* Retrieve only relevant chunks\n",
    "* Apply hierarchical summarization for large content\n",
    "\n",
    "---\n",
    "\n",
    "### 7. How Do You Evaluate LLM Responses?\n",
    "\n",
    "* Automated metrics (ROUGE, BLEU, similarity scores)\n",
    "* Human review\n",
    "* Regression tests\n",
    "* Task success metrics\n",
    "* User feedback\n",
    "\n",
    "---\n",
    "\n",
    "### 8. How Do You Reduce Hallucinations?\n",
    "\n",
    "* Use RAG\n",
    "* Require citations\n",
    "* Constrain prompts\n",
    "* Add verification step\n",
    "* Limit model freedom\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Embedding Strategies\n",
    "\n",
    "* Optimal chunk size & overlap\n",
    "* Metadata enrichment\n",
    "* Hybrid search (keyword + vector)\n",
    "* Domain-specific embeddings\n",
    "* Periodic re-embedding\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Choosing Between Multiple LLM Providers\n",
    "\n",
    "Consider:\n",
    "Accuracy, cost, latency, privacy, reliability, tool support.\n",
    "Use **dynamic routing** to balance quality and cost.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 System Design Scenarios\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Design a ChatGPT-Like System\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "UI → API Gateway → Orchestrator → Prompt Manager →\n",
    "LLM → Memory → Moderation → Logging & Monitoring\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Design a Legal Document Assistant\n",
    "\n",
    "RAG over legal corpus → citation engine → compliance controls → audit logs → role-based access.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Design an AI Tutor Platform\n",
    "\n",
    "Student profile → knowledge retrieval → adaptive prompt generation → progress tracking → feedback engine.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Design a Code Review Assistant\n",
    "\n",
    "Code ingestion → static analysis → LLM review → suggestion ranking → CI/CD integration.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Design a Real-Time Customer Support AI\n",
    "\n",
    "Customer query → CRM lookup → RAG → LLM response → sentiment detection → human handoff → learning loop.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Advanced Level — Production & Scalability\n",
    "\n",
    "### 3.1 Engineering & Reliability\n",
    "\n",
    "1. Design scalable RAG architecture for millions of documents.\n",
    "2. How do you implement caching in GenAI?\n",
    "3. How do you handle LLM rate limits?\n",
    "4. How do you build prompt versioning & rollback?\n",
    "5. How do you design observability for GenAI?\n",
    "6. How do you manage model drift?\n",
    "7. How do you implement A/B testing for prompts?\n",
    "8. How do you detect and prevent prompt injection?\n",
    "9. How do you ensure data privacy & compliance?\n",
    "10. How do you handle model outages?\n",
    "\n",
    "### 3.2 Real-World Design\n",
    "\n",
    "1. Design AI-powered CRM system.\n",
    "2. Design enterprise knowledge assistant.\n",
    "3. Design medical diagnosis assistant.\n",
    "4. Design fraud detection AI system.\n",
    "5. Design AI DevOps assistant.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Expert Level — Strategic & Research\n",
    "\n",
    "### 4.1 Deep System Thinking\n",
    "\n",
    "1. Design multi-agent autonomous system for enterprise automation.\n",
    "2. How do you design long-term memory for AI?\n",
    "3. How do you handle multimodal GenAI pipelines?\n",
    "4. How do you evaluate business ROI of GenAI?\n",
    "5. How do you balance cost vs quality in LLM systems?\n",
    "6. How do you architect GenAI microservices?\n",
    "7. How do you manage continuous learning pipelines?\n",
    "8. How do you handle model governance at scale?\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Master Level — Leadership & Vision\n",
    "\n",
    "### 5.1 Executive-Level Questions\n",
    "\n",
    "1. How would you build a GenAI platform for a large enterprise?\n",
    "2. How do you create company-wide AI governance?\n",
    "3. How do you scale GenAI from prototype to global product?\n",
    "4. How do you align GenAI systems with business strategy?\n",
    "5. How do you measure success of AI transformation?\n",
    "\n",
    "---\n",
    "\n",
    "## High-Frequency Interview Focus Areas\n",
    "\n",
    "| Area                    | Importance  |\n",
    "| ----------------------- | ----------- |\n",
    "| RAG & Vector Search     | Very High   |\n",
    "| Scalability             | Very High   |\n",
    "| Security & Compliance   | Very High   |\n",
    "| Evaluation & Monitoring | High        |\n",
    "| Cost Optimization       | High        |\n",
    "| Multi-Agent Systems     | Medium–High |\n",
    "| Multimodal AI           | Medium–High |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
