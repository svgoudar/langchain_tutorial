{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec57664c",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Content Filtering \n",
    "\n",
    "**Content filtering** is the process of **detecting, blocking, or modifying** generated or user-provided text that violates safety, policy, or business rules before it is stored, displayed, or acted upon.\n",
    "\n",
    "It enforces **what is allowed** and **what is forbidden** in the system.\n",
    "\n",
    "---\n",
    "\n",
    "### Where It Fits in the Pipeline\n",
    "\n",
    "```\n",
    "User Input / LLM Output\n",
    "        ↓\n",
    "Content Filter ── allowed → Continue\n",
    "        ↓ blocked\n",
    "Remove / Replace / Reject / Log\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Types of Content Filtering\n",
    "\n",
    "| Type                 | Purpose                   |\n",
    "| -------------------- | ------------------------- |\n",
    "| Keyword filtering    | Block known harmful terms |\n",
    "| Pattern filtering    | Detect unsafe expressions |\n",
    "| Category filtering   | Enforce policy classes    |\n",
    "| Context filtering    | Block unsafe meaning      |\n",
    "| Compliance filtering | Meet legal standards      |\n",
    "\n",
    "---\n",
    "\n",
    "### Basic Keyword Filter\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "BLOCKED_WORDS = [\"password\", \"secret\", \"credit card\"]\n",
    "\n",
    "def keyword_filter(text):\n",
    "    lower = text.lower()\n",
    "    for word in BLOCKED_WORDS:\n",
    "        if word in lower:\n",
    "            return False\n",
    "    return True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Pattern-Based Filtering\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "BLOCK_PATTERNS = [\n",
    "    r\"\\b\\d{16}\\b\",         # credit card number pattern\n",
    "    r\"api[_\\- ]?key\",\n",
    "]\n",
    "\n",
    "def pattern_filter(text):\n",
    "    for pattern in BLOCK_PATTERNS:\n",
    "        if re.search(pattern, text.lower()):\n",
    "            return False\n",
    "    return True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Category-Level Filtering\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "def category_filter(text):\n",
    "    categories = moderation_model.classify(text)\n",
    "    return not categories[\"self_harm\"] and not categories[\"illegal\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Full Filtering Pipeline\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "def is_content_safe(text):\n",
    "    if not keyword_filter(text):\n",
    "        return False\n",
    "    if not pattern_filter(text):\n",
    "        return False\n",
    "    if not category_filter(text):\n",
    "        return False\n",
    "    return True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Enforcement Layer\n",
    "\n",
    "```python\n",
    "def safe_response(text):\n",
    "    if not is_content_safe(text):\n",
    "        return \"Content blocked by safety filter.\"\n",
    "    return text\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Mental Model\n",
    "\n",
    "```\n",
    "Content Filtering = Safety firewall for your system\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* Works on both user input and LLM output\n",
    "* Uses multiple detection layers\n",
    "* Mandatory for compliance and safety\n",
    "* Should run continuously in production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2112d8da",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
