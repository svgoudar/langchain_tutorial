{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3cd19b2",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Maximal Marginal Relevance (MMR)\n",
    "\n",
    "\n",
    "**Maximal Marginal Relevance (MMR)** is a **retrieval re-ranking strategy** that balances:\n",
    "\n",
    "* **Relevance** to the query\n",
    "* **Diversity** among retrieved documents\n",
    "\n",
    "> MMR reduces redundancy by avoiding multiple chunks that say the same thing.\n",
    "\n",
    "It is commonly used **after similarity search** and **before sending context to the LLM**.\n",
    "\n",
    "---\n",
    "\n",
    "### Why MMR Is Needed\n",
    "\n",
    "Pure similarity search often returns:\n",
    "\n",
    "* Highly similar chunks\n",
    "* Near-duplicate passages\n",
    "* Redundant context\n",
    "\n",
    "This causes:\n",
    "\n",
    "* Wasted context window\n",
    "* Lower answer quality\n",
    "* Higher hallucination risk\n",
    "\n",
    "MMR ensures the retrieved set covers **different aspects** of the query.\n",
    "\n",
    "---\n",
    "\n",
    "### Conceptual Goal\n",
    "\n",
    "```\n",
    "Maximize relevance\n",
    "AND\n",
    "Minimize redundancy\n",
    "```\n",
    "\n",
    "MMR explicitly trades off between the two.\n",
    "\n",
    "---\n",
    "\n",
    "### The MMR Formula (Intuition)\n",
    "\n",
    "For each candidate document ( d ):\n",
    "\n",
    "```\n",
    "MMR(d) = λ · sim(d, query)\n",
    "         − (1 − λ) · max sim(d, selected_docs)\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "* `sim(d, query)` → relevance\n",
    "* `sim(d, selected_docs)` → redundancy\n",
    "* `λ` (lambda) ∈ [0, 1] controls the tradeoff\n",
    "\n",
    "---\n",
    "\n",
    "### Lambda (λ) Explained\n",
    "\n",
    "| λ value | Behavior                                   |\n",
    "| ------- | ------------------------------------------ |\n",
    "| 1.0     | Pure relevance (same as similarity search) |\n",
    "| 0.5     | Balanced relevance + diversity             |\n",
    "| 0.0     | Maximum diversity (rarely useful)          |\n",
    "\n",
    "**Typical production value:** `λ = 0.5–0.7`\n",
    "\n",
    "---\n",
    "\n",
    "### Where MMR Fits in RAG\n",
    "\n",
    "```\n",
    "Query\n",
    "  ↓\n",
    "Vector / Hybrid Retrieval (Top-N)\n",
    "  ↓\n",
    "MMR Selection (Diverse Top-K)\n",
    "  ↓\n",
    "LLM\n",
    "```\n",
    "\n",
    "MMR is a **query-time** operation.\n",
    "\n",
    "---\n",
    "\n",
    "### How MMR Works Step-by-Step\n",
    "\n",
    "1. Select the most relevant document\n",
    "2. For remaining candidates:\n",
    "\n",
    "   * Penalize similarity to already selected docs\n",
    "3. Iteratively select documents that add **new information**\n",
    "4. Stop when K documents are selected\n",
    "\n",
    "---\n",
    "\n",
    "### MMR vs Similarity Search\n",
    "\n",
    "| Aspect             | Similarity Search | MMR                   |\n",
    "| ------------------ | ----------------- | --------------------- |\n",
    "| Goal               | Relevance only    | Relevance + diversity |\n",
    "| Redundancy         | High              | Low                   |\n",
    "| Context efficiency | Lower             | Higher                |\n",
    "| LLM answer quality | Medium            | Higher                |\n",
    "\n",
    "---\n",
    "\n",
    "### MMR Demonstration (LangChain)\n",
    "\n",
    "#### Using MMR in a Retriever\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718b6f3",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Use the existing vectorstore that was already created in a previous cell\n",
    "# If you need to recreate it, uncomment the line below:\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,          # final results\n",
    "        \"fetch_k\": 20,   # initial candidate pool\n",
    "        \"lambda_mult\": 0.6\n",
    "    }\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "* `fetch_k`: how many to retrieve initially\n",
    "* `k`: how many to return after MMR\n",
    "* `lambda_mult`: λ value\n",
    "\n",
    "---\n",
    "\n",
    "### Querying with MMR\n",
    "\n",
    "```python\n",
    "docs = retriever.get_relevant_documents(\n",
    "    \"How does Jira ticket escalation work?\"\n",
    ")\n",
    "```\n",
    "\n",
    "Returned documents:\n",
    "\n",
    "* Relevant\n",
    "* Non-redundant\n",
    "* Cover multiple facets\n",
    "\n",
    "---\n",
    "\n",
    "### MMR vs Reranking\n",
    "\n",
    "| Aspect    | MMR       | Reranking   |\n",
    "| --------- | --------- | ----------- |\n",
    "| Type      | Heuristic | Model-based |\n",
    "| Cost      | Low       | High        |\n",
    "| Latency   | Very low  | Higher      |\n",
    "| Precision | Medium    | High        |\n",
    "| Diversity | High      | Medium      |\n",
    "\n",
    "**Production pattern:**\n",
    "`Hybrid Search → MMR → Reranker → LLM`\n",
    "\n",
    "---\n",
    "\n",
    "### When MMR Helps Most\n",
    "\n",
    "* Highly repetitive documents\n",
    "* Long manuals or policies\n",
    "* Logs and ticket histories\n",
    "* RAG systems with chunk overlap\n",
    "* When context window is tight\n",
    "\n",
    "---\n",
    "\n",
    "### When MMR Is Less Useful\n",
    "\n",
    "* Very small datasets\n",
    "* Highly precise fact lookup\n",
    "* When reranking is already applied aggressively\n",
    "\n",
    "---\n",
    "\n",
    "### MMR and Chunk Overlap\n",
    "\n",
    "Chunk overlap increases redundancy.\n",
    "MMR counteracts this by:\n",
    "\n",
    "* Selecting only one chunk from overlapping regions\n",
    "* Preserving coverage while reducing noise\n",
    "\n",
    "---\n",
    "\n",
    "### Production Tuning Guidelines\n",
    "\n",
    "### Recommended Defaults\n",
    "\n",
    "```text\n",
    "fetch_k = 20–50\n",
    "k = 3–7\n",
    "lambda = 0.5–0.7\n",
    "```\n",
    "\n",
    "### Tradeoffs\n",
    "\n",
    "* Higher `fetch_k` → better diversity, higher cost\n",
    "* Lower `lambda` → more diversity, less relevance\n",
    "\n",
    "---\n",
    "\n",
    "### Common Mistakes\n",
    "\n",
    "#### Using MMR alone\n",
    "\n",
    "❌ Does not replace reranking\n",
    "\n",
    "#### Very low lambda\n",
    "\n",
    "❌ Results become off-topic\n",
    "\n",
    "#### Small fetch_k\n",
    "\n",
    "❌ No diversity benefit\n",
    "\n",
    "#### Applying MMR at ingestion time\n",
    "\n",
    "❌ Must be query-time only\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "* Use MMR after initial retrieval\n",
    "* Combine with hybrid search\n",
    "* Tune lambda per domain\n",
    "* Log selected chunks for observability\n",
    "* Pair with reranking for accuracy\n",
    "\n",
    "---\n",
    "\n",
    "### Interview-Ready Summary\n",
    "\n",
    "> “Maximal Marginal Relevance (MMR) is a retrieval strategy that balances relevance to the query with diversity among selected documents. It reduces redundancy in RAG systems and improves context efficiency.”\n",
    "\n",
    "---\n",
    "\n",
    "### Rule of Thumb\n",
    "\n",
    "* **Similarity search → relevance**\n",
    "* **MMR → diversity**\n",
    "* **Reranker → precision**\n",
    "* **Best RAG = all three**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
