{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5fe5599",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Stuff Chain\n",
    "\n",
    "\n",
    "A **Stuff Chain** is a LangChain abstraction that **“stuffs” all input documents or text chunks into a single prompt** and sends them to the LLM **in one call**.\n",
    "\n",
    "> There is **no splitting, no iteration, no aggregation** — everything is passed at once.\n",
    "\n",
    "It is the **simplest** document-processing chain in LangChain.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Stuff Chain Exists\n",
    "\n",
    "Stuff chain exists for:\n",
    "\n",
    "* Small inputs\n",
    "* Quick summarization\n",
    "* Simple RAG demos\n",
    "* Lowest latency workflows\n",
    "\n",
    "It assumes:\n",
    "\n",
    "* The entire input **fits within the model’s context window**\n",
    "* The model can reason over all content at once\n",
    "\n",
    "---\n",
    "\n",
    "### Conceptual Flow\n",
    "\n",
    "```\n",
    "All Documents\n",
    "   ↓\n",
    "Concatenate (stuff)\n",
    "   ↓\n",
    "Single Prompt\n",
    "   ↓\n",
    "LLM\n",
    "   ↓\n",
    "Final Output\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### How Stuff Chain Works Internally\n",
    "\n",
    "1. Take all documents\n",
    "2. Concatenate their contents\n",
    "3. Inject into a single prompt variable\n",
    "4. Call the LLM once\n",
    "\n",
    "No intermediate steps are stored.\n",
    "\n",
    "---\n",
    "\n",
    "### Basic Stuff Chain Demonstration\n",
    "\n",
    "#### Step 1: Define the Prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eec6356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Answer the question using the following context:\\n{context}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481b086",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2: Create the Stuff Chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "309fed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains.summarize import load_summarize_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ea465a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### Step 3: Invoke the Chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60fad9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are some applications of Artificial Intelligence mentioned in the context?\n",
      "\n",
      "Some applications of Artificial Intelligence mentioned include chatbots, translation services, sentiment analysis, facial recognition, autonomous vehicles, and medical image analysis.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create sample documents\n",
    "documents = [\n",
    "    Document(page_content=\"Artificial Intelligence is transforming industries worldwide. Machine learning algorithms enable computers to learn from data and improve their performance over time without explicit programming.\"),\n",
    "    Document(page_content=\"Natural Language Processing allows machines to understand and generate human language. Applications include chatbots, translation services, and sentiment analysis.\"),\n",
    "    Document(page_content=\"Computer vision enables machines to interpret and understand visual information from the world. It powers technologies like facial recognition, autonomous vehicles, and medical image analysis.\")\n",
    "]\n",
    "\n",
    "result = chain.invoke({\"input_documents\": documents})\n",
    "print(result[\"output_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b5660f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "All documents are stuffed into `{context}`.\n",
    "\n",
    "---\n",
    "\n",
    "### Internal Execution (Simplified)\n",
    "\n",
    "```\n",
    "context = join(doc1, doc2, doc3, ...)\n",
    "response = LLM(prompt(context))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Common Use Cases\n",
    "\n",
    "* Small document summarization\n",
    "* FAQ answering\n",
    "* Short reports\n",
    "* RAG with few chunks\n",
    "* Prototyping and demos\n",
    "\n",
    "---\n",
    "\n",
    "### Stuff Chain vs MapReduce\n",
    "\n",
    "| Aspect        | Stuff Chain | MapReduce  |\n",
    "| ------------- | ----------- | ---------- |\n",
    "| Scalability   | Low         | High       |\n",
    "| Latency       | Low         | Medium     |\n",
    "| Parallelism   | ❌           | ✅          |\n",
    "| Context usage | High        | Controlled |\n",
    "\n",
    "---\n",
    "\n",
    "### Stuff Chain vs Refine\n",
    "\n",
    "| Aspect                | Stuff | Refine |\n",
    "| --------------------- | ----- | ------ |\n",
    "| Order sensitivity     | Low   | High   |\n",
    "| Accuracy on long docs | Low   | High   |\n",
    "| Latency               | Low   | High   |\n",
    "\n",
    "---\n",
    "\n",
    "### Limitations of Stuff Chain\n",
    "\n",
    "* ❌ Breaks if input exceeds context window\n",
    "* ❌ Expensive for large documents\n",
    "* ❌ No partial fault tolerance\n",
    "* ❌ Legacy abstraction\n",
    "\n",
    "---\n",
    "\n",
    "### Stuff Chain in RAG Pipelines\n",
    "\n",
    "Stuff chain is commonly used when:\n",
    "\n",
    "* Retriever returns **few, small chunks**\n",
    "* You want a **single grounded answer**\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Retriever → Stuff Chain → Answer\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Stuff Chain vs LCEL (Modern Approach)\n",
    "\n",
    "#### Stuff Chain (Legacy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4a0eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'), llm=ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x0000018D9025D7F0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000018D9025C650>, root_client=<openai.OpenAI object at 0x0000018D9025D550>, root_async_client=<openai.AsyncOpenAI object at 0x0000018D9025D460>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='text')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic.chains.summarize import load_summarize_chain\n",
    "load_summarize_chain(llm=llm, chain_type=\"stuff\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500d0cb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### LCEL Equivalent (Conceptual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf857c9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "LCEL provides:\n",
    "\n",
    "* Better composability\n",
    "* Streaming\n",
    "* Validation\n",
    "* Future-proof design\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use Stuff Chain\n",
    "\n",
    "* Input size is guaranteed small\n",
    "* Latency matters more than scalability\n",
    "* Simple QA or summarization\n",
    "* Learning LangChain basics\n",
    "\n",
    "---\n",
    "\n",
    "### When NOT to Use Stuff Chain\n",
    "\n",
    "* Large documents\n",
    "* Unbounded user input\n",
    "* Production RAG systems\n",
    "* Compliance-critical systems\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "* Limit number of retrieved documents\n",
    "* Enforce chunk size\n",
    "* Use low temperature\n",
    "* Validate token counts\n",
    "* Add fallbacks for overflow\n",
    "\n",
    "---\n",
    "\n",
    "### Interview-Ready Summary\n",
    "\n",
    "> “A Stuff Chain in LangChain concatenates all input documents into a single prompt and processes them in one LLM call. It is fast and simple but limited by context window size and has largely been superseded by LCEL for production systems.”\n",
    "\n",
    "---\n",
    "\n",
    "### Rule of Thumb\n",
    "\n",
    "* **Few small documents → Stuff**\n",
    "* **Many large documents → MapReduce or Refine**\n",
    "* **Modern production → LCEL-based RAG**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
