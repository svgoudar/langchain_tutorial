{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd8ee679",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## System / Human / AI Messages (LangChain)\n",
    "\n",
    "### What Messages Are\n",
    "\n",
    "In **LangChain**, **messages** are **typed, role-based units of conversation** used by **chat models**.\n",
    "They define **who said what** and **how the model should interpret it**.\n",
    "\n",
    "> Chat models do not consume raw text.\n",
    "> They consume **ordered message objects**.\n",
    "\n",
    "---\n",
    "\n",
    "### The Three Core Message Types\n",
    "\n",
    "### System Message\n",
    "\n",
    "#### What It Is\n",
    "\n",
    "A **System Message** defines **global instructions** and **behavioral constraints** for the model.\n",
    "\n",
    "> It answers: *“How should the assistant behave?”*\n",
    "\n",
    "#### Characteristics\n",
    "\n",
    "* Highest priority\n",
    "* Not visible to the end user\n",
    "* Applies to the entire conversation\n",
    "* Overrides user intent when conflicting\n",
    "\n",
    "#### Demonstration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ac018c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='You are an IT support assistant.', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "SystemMessage(content=\"You are an IT support assistant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346fa22a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Human Message\n",
    "\n",
    "#### What It Is\n",
    "\n",
    "A **Human Message** represents **user input**.\n",
    "\n",
    "> It answers: *“What does the user want?”*\n",
    "\n",
    "#### Characteristics\n",
    "\n",
    "* Comes from the user\n",
    "* Can appear multiple times\n",
    "* Lower priority than System messages\n",
    "\n",
    "#### Demonstration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d51167e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='Email service is down', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "HumanMessage(content=\"Email service is down\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d80236d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### AI Message\n",
    "\n",
    "#### What It Is\n",
    "\n",
    "An **AI Message** represents the **assistant’s response**.\n",
    "\n",
    "> It answers: *“What did the model say?”*\n",
    "\n",
    "#### Characteristics\n",
    "\n",
    "* Generated by the model\n",
    "* Can include tool calls\n",
    "* Can be stored as chat history\n",
    "\n",
    "#### Demonstration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ae8307c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I will help you resolve the issue.', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "AIMessage(content=\"I will help you resolve the issue.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b358d17",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Message Priority Hierarchy (Critical)\n",
    "\n",
    "```\n",
    "System  >  Human  >  AI\n",
    "```\n",
    "\n",
    "If a Human message conflicts with a System message,\n",
    "the **System message always wins**.\n",
    "\n",
    "---\n",
    "\n",
    "### Messages in a Conversation\n",
    "\n",
    "#### Typical Message Flow\n",
    "\n",
    "```\n",
    "System → Human → AI → Human → AI → ...\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3537255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is RAG?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='RAG stands for Retrieval-Augmented Generation', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[\n",
    "  SystemMessage(\"You are a helpful assistant\"),\n",
    "  HumanMessage(\"What is RAG?\"),\n",
    "  AIMessage(\"RAG stands for Retrieval-Augmented Generation\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ced8fa",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Using Messages with Chat Models\n",
    "\n",
    "#### Direct Invocation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5b0d035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCEL stands for \"Language-Culture-Experience-Learning.\" It is an educational approach that emphasizes the interconnection among language, culture, and experiential learning. Here’s a breakdown of its components:\n",
      "\n",
      "1. **Language**: LCEL prioritizes language acquisition as a means of communication and understanding. This involves not just vocabulary and grammar, but also the pragmatic aspects of language use in different contexts.\n",
      "\n",
      "2. **Culture**: Understanding the cultural contexts in which a language is spoken is crucial. This involves exploring traditions, values, social norms, and practices of the communities that use the language, which can greatly enhance learners' comprehension and empathy.\n",
      "\n",
      "3. **Experience**: LCEL emphasizes learning through real-life experiences. This can include hands-on activities, immersive experiences, and situational learning that allow students to apply their language skills in authentic contexts.\n",
      "\n",
      "4. **Learning**: The overarching goal of LCEL is to foster holistic learning. This approach encourages critical thinking, adaptability, and a deeper appreciation of the interconnectedness of language and culture through direct experiences.\n",
      "\n",
      "By integrating these elements, LCEL can facilitate more meaningful language learning, helping students to not only understand a language but also to communicate effectively within its cultural frameworks. This method can be particularly effective in promoting cultural competence and global awareness in learners.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "response = llm.invoke([\n",
    "    SystemMessage(content=\"You are a teacher.\"),\n",
    "    HumanMessage(content=\"Explain LCEL.\")\n",
    "])\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54444d5b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Messages via ChatPromptTemplate (Recommended)\n",
    "\n",
    "#### Declarative Message Definition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35ade0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a326c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "LangChain converts these into message objects internally.\n",
    "\n",
    "---\n",
    "\n",
    "### MessagesPlaceholder (Dynamic Messages)\n",
    "\n",
    "#### Injecting Chat History\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb156ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a support assistant.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a96fe",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Used for:\n",
    "\n",
    "* Conversation memory\n",
    "* Tool history\n",
    "* Agent scratchpad\n",
    "\n",
    "---\n",
    "\n",
    "### AI Messages with Tool Calls\n",
    "\n",
    "#### Tool-Aware AI Messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38eafc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"How many tickets are there in Jira?\")\n",
    "print(response.tool_calls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f038c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "AIMessage can contain:\n",
    "\n",
    "* Text\n",
    "* Tool name\n",
    "* Tool arguments\n",
    "\n",
    "This enables agent workflows.\n",
    "\n",
    "---\n",
    "\n",
    "### Messages in Agents\n",
    "\n",
    "#### Required Agent Messages\n",
    "\n",
    "Agents rely on:\n",
    "\n",
    "* HumanMessage → user intent\n",
    "* AIMessage → reasoning & tool calls\n",
    "* SystemMessage → safety and behavior\n",
    "\n",
    "The agent scratchpad is a **sequence of AI and tool messages**.\n",
    "\n",
    "---\n",
    "\n",
    "### Messages in RAG\n",
    "\n",
    "#### Context as Human Message\n",
    "\n",
    "```python\n",
    "(\"human\", \"Context:\\n{context}\\n\\nQuestion:\\n{input}\")\n",
    "```\n",
    "\n",
    "Retrieved documents are injected into Human messages so the model can ground its answer.\n",
    "\n",
    "---\n",
    "\n",
    "### Common Mistakes\n",
    "\n",
    "#### Putting instructions in Human messages\n",
    "\n",
    "❌ Weak enforcement\n",
    "\n",
    "#### Overloading System messages\n",
    "\n",
    "❌ Reduced model compliance\n",
    "\n",
    "#### Exposing AI reasoning\n",
    "\n",
    "❌ Security risk\n",
    "\n",
    "#### Manually concatenating messages\n",
    "\n",
    "❌ Breaks structure\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "* Use **System messages** for rules and behavior\n",
    "* Use **Human messages** only for user input\n",
    "* Use **AI messages** only for model output\n",
    "* Keep system instructions concise\n",
    "* Never expose chain-of-thought\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use Each Message Type\n",
    "\n",
    "| Message Type        | Use Case                 |\n",
    "| ------------------- | ------------------------ |\n",
    "| System              | Role, rules, constraints |\n",
    "| Human               | User question or input   |\n",
    "| AI                  | Model-generated response |\n",
    "| MessagesPlaceholder | Memory / tools           |\n",
    "\n",
    "---\n",
    "\n",
    "### Interview-Ready Summary\n",
    "\n",
    "> “System, Human, and AI messages are role-based conversation units in LangChain. System messages define behavior, Human messages express user intent, and AI messages contain model output. Their strict hierarchy enables safe, agentic, and RAG-based systems.”\n",
    "\n",
    "---\n",
    "\n",
    "### Rule of Thumb\n",
    "\n",
    "* **Rules → System**\n",
    "* **Questions → Human**\n",
    "* **Answers → AI**\n",
    "* **History → MessagesPlaceholder**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
