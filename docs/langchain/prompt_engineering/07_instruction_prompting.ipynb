{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d94007b5",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Instruction Tuning (LangChain & LLM Perspective)\n",
    "\n",
    "### What Instruction Tuning Is\n",
    "\n",
    "**Instruction tuning** is a **model training technique** where a pre-trained LLM is further trained on **(instruction, input, output)** triples so that it learns to **follow human instructions reliably**.\n",
    "\n",
    "> Instruction tuning changes the **model’s weights**.\n",
    "> Prompting changes only **runtime behavior**.\n",
    "\n",
    "This is **not a LangChain feature**, but LangChain is often used to **consume instruction-tuned models**.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Instruction Tuning Exists\n",
    "\n",
    "Base LLMs:\n",
    "\n",
    "* Predict next tokens\n",
    "* Do not inherently follow instructions well\n",
    "\n",
    "Instruction-tuned models:\n",
    "\n",
    "* Understand commands\n",
    "* Follow task intent\n",
    "* Generalize across tasks\n",
    "* Are safer and more aligned\n",
    "\n",
    "Most modern chat models are **already instruction-tuned**.\n",
    "\n",
    "---\n",
    "\n",
    "### Instruction Tuning vs Prompting\n",
    "\n",
    "| Aspect            | Instruction Tuning | Prompting     |\n",
    "| ----------------- | ------------------ | ------------- |\n",
    "| Model weights     | ✅ Changed          | ❌ Not changed |\n",
    "| Training required | ✅ Yes              | ❌ No          |\n",
    "| Latency           | Lower              | Higher        |\n",
    "| Flexibility       | Lower              | Higher        |\n",
    "| Deployment        | Slower             | Immediate     |\n",
    "\n",
    "---\n",
    "\n",
    "### Where Instruction Tuning Fits in the Stack\n",
    "\n",
    "```\n",
    "Pretraining\n",
    "   ↓\n",
    "Instruction Tuning\n",
    "   ↓\n",
    "Chat / Instruct Model\n",
    "   ↓\n",
    "LangChain (prompts, RAG, agents)\n",
    "```\n",
    "\n",
    "LangChain **assumes** instruction-tuned behavior.\n",
    "\n",
    "---\n",
    "\n",
    "### Instruction-Tuned Models (Examples)\n",
    "\n",
    "Common instruction-tuned models:\n",
    "\n",
    "* GPT-4 / GPT-4o / GPT-4o-mini\n",
    "* Claude-3 family\n",
    "* Gemini 1.5\n",
    "* LLaMA-2-Chat / LLaMA-3-Instruct\n",
    "* Mistral-Instruct\n",
    "\n",
    "These models already understand:\n",
    "\n",
    "* “Explain…”\n",
    "* “Classify…”\n",
    "* “Summarize…”\n",
    "\n",
    "---\n",
    "\n",
    "### Instruction Format (Training Data)\n",
    "\n",
    "#### Typical Instruction Tuning Sample\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"instruction\": \"Classify the issue severity\",\n",
    "  \"input\": \"Database is down for all users\",\n",
    "  \"output\": \"High\"\n",
    "}\n",
    "```\n",
    "\n",
    "Thousands to millions of such examples are used.\n",
    "\n",
    "---\n",
    "\n",
    "### Demonstration: Instruction Tuning Concept (Pseudo)\n",
    "\n",
    "### Base Model Behavior (Before)\n",
    "\n",
    "```text\n",
    "Input: \"Classify severity: Database is down\"\n",
    "Output: \"Databases store data in tables...\"\n",
    "```\n",
    "\n",
    "### After Instruction Tuning\n",
    "\n",
    "```text\n",
    "Input: \"Classify severity: Database is down\"\n",
    "Output: \"High\"\n",
    "```\n",
    "\n",
    "The **model learned the task**, not the prompt.\n",
    "\n",
    "---\n",
    "\n",
    "### Instruction Tuning vs Few-shot Prompting\n",
    "\n",
    "| Aspect      | Instruction Tuning | Few-shot Prompting |\n",
    "| ----------- | ------------------ | ------------------ |\n",
    "| Persistence | Permanent          | Temporary          |\n",
    "| Token cost  | None               | High               |\n",
    "| Accuracy    | High               | Medium             |\n",
    "| Setup       | Expensive          | Easy               |\n",
    "\n",
    "---\n",
    "\n",
    "### Instruction Tuning vs Fine-tuning (Clarification)\n",
    "\n",
    "Instruction tuning **is a type of fine-tuning**.\n",
    "\n",
    "### Fine-tuning Types\n",
    "\n",
    "* Domain fine-tuning (medical, legal)\n",
    "* Style fine-tuning\n",
    "* **Instruction tuning** (task-following)\n",
    "\n",
    "Instruction tuning focuses on **behavior**, not knowledge.\n",
    "\n",
    "---\n",
    "\n",
    "### Demonstration: Using an Instruction-Tuned Model in LangChain\n",
    "\n",
    "#### Zero-shot Prompt (Works Because of Instruction Tuning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8719714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The severity of a \"Database is down\" issue can typically be classified as **Critical** or **High**. This classification is due to the following reasons:\\n\\n1. **Impact on Operations**: A down database can halt operations for applications that rely on it, affecting business processes and user access.\\n2. **Data Accessibility**: Users and systems cannot access or manipulate data, which can lead to significant disruptions.\\n3. **Potential Financial Loss**: If the database is critical to revenue-generating activities, downtime can lead to financial losses.\\n4. **Urgency for Resolution**: Immediate action is usually required to restore service and minimize impact.\\n\\nIn summary, the severity classification would generally be **Critical** or **High**, depending on the specific context and business impact.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "llm.invoke(\"Classify severity: Database is down\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2519758a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This works **without examples** because the model is instruction-tuned.\n",
    "\n",
    "---\n",
    "\n",
    "### What LangChain Does NOT Do\n",
    "\n",
    "LangChain does **not**:\n",
    "\n",
    "* Train models\n",
    "* Instruction-tune models\n",
    "* Modify weights\n",
    "\n",
    "LangChain:\n",
    "\n",
    "* Assumes instruction-following\n",
    "* Orchestrates prompts, tools, RAG, agents\n",
    "\n",
    "---\n",
    "\n",
    "### When You Actually Need Instruction Tuning\n",
    "\n",
    "Use instruction tuning when:\n",
    "\n",
    "* Prompting fails consistently\n",
    "* You have a fixed task\n",
    "* High-volume inference\n",
    "* Latency matters\n",
    "* Domain is stable\n",
    "\n",
    "---\n",
    "\n",
    "### When You Should NOT Instruction-Tune\n",
    "\n",
    "Avoid when:\n",
    "\n",
    "* Task changes often\n",
    "* You lack large datasets\n",
    "* RAG can solve the problem\n",
    "* You need fast iteration\n",
    "\n",
    "---\n",
    "\n",
    "### Instruction Tuning vs RAG\n",
    "\n",
    "| Aspect           | Instruction Tuning | RAG |\n",
    "| ---------------- | ------------------ | --- |\n",
    "| Adds knowledge   | ❌                  | ✅   |\n",
    "| Changes behavior | ✅                  | ❌   |\n",
    "| Data freshness   | ❌                  | ✅   |\n",
    "| Cost             | High               | Low |\n",
    "\n",
    "Best practice:\n",
    "\n",
    "* **Instruction tuning for behavior**\n",
    "* **RAG for knowledge**\n",
    "\n",
    "---\n",
    "\n",
    "### Instruction Tuning + LangChain (Best Practice)\n",
    "\n",
    "```\n",
    "Instruction-tuned model\n",
    "   ↓\n",
    "LangChain PromptTemplate\n",
    "   ↓\n",
    "RAG / Agents / Tools\n",
    "```\n",
    "\n",
    "LangChain sits **on top** of instruction-tuned models.\n",
    "\n",
    "---\n",
    "\n",
    "### Common Misconceptions\n",
    "\n",
    "#### Instruction tuning replaces prompting\n",
    "\n",
    "❌ It reduces prompt complexity, but does not eliminate prompts.\n",
    "\n",
    "#### Instruction tuning adds new knowledge\n",
    "\n",
    "❌ It adds behavior, not facts.\n",
    "\n",
    "#### LangChain does instruction tuning\n",
    "\n",
    "❌ LangChain consumes tuned models.\n",
    "\n",
    "---\n",
    "\n",
    "### Interview-Ready Summary\n",
    "\n",
    "> “Instruction tuning is a fine-tuning technique where LLMs are trained on instruction–response pairs to follow human commands reliably. LangChain assumes instruction-tuned models and builds higher-level orchestration like prompts, RAG, and agents on top of them.”\n",
    "\n",
    "---\n",
    "\n",
    "### Rule of Thumb\n",
    "\n",
    "* **Behavior problem → Instruction tuning**\n",
    "* **Knowledge problem → RAG**\n",
    "* **Fast iteration → Prompting**\n",
    "* **Production scale → Instruction-tuned model + LangChain**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
