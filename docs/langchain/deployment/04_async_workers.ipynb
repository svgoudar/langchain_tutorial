{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa5f1b3",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Async Workers \n",
    "\n",
    "\n",
    "**Async workers** are background execution units that process tasks **concurrently** without blocking the main application thread.\n",
    "They allow the system to handle **many long-running or I/O-bound jobs** efficiently.\n",
    "\n",
    "They are fundamental for:\n",
    "\n",
    "* High-throughput APIs\n",
    "* LLM pipelines\n",
    "* Data processing systems\n",
    "* Event-driven architectures\n",
    "\n",
    "---\n",
    "\n",
    "### Why Async Workers Matter\n",
    "\n",
    "Without async workers:\n",
    "\n",
    "```\n",
    "Request → Blocking work → Server stalls → Timeouts\n",
    "```\n",
    "\n",
    "With async workers:\n",
    "\n",
    "```\n",
    "Requests handled instantly + work processed concurrently\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Where Async Workers Fit\n",
    "\n",
    "```\n",
    "Client → API → Task Queue → Async Workers → Database / LLM / Storage\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Native Python Async Workers (asyncio)\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def worker(name, queue):\n",
    "    while True:\n",
    "        job = await queue.get()\n",
    "        print(f\"{name} processing {job}\")\n",
    "        await asyncio.sleep(2)\n",
    "        queue.task_done()\n",
    "\n",
    "async def main():\n",
    "    queue = asyncio.Queue()\n",
    "\n",
    "    workers = [asyncio.create_task(worker(f\"W{i}\", queue)) for i in range(3)]\n",
    "\n",
    "    for i in range(10):\n",
    "        await queue.put(f\"job-{i}\")\n",
    "\n",
    "    await queue.join()\n",
    "\n",
    "    for w in workers:\n",
    "        w.cancel()\n",
    "\n",
    "asyncio.run(main())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Async Workers in FastAPI\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "import asyncio\n",
    "\n",
    "app = FastAPI()\n",
    "queue = asyncio.Queue()\n",
    "\n",
    "async def worker():\n",
    "    while True:\n",
    "        job = await queue.get()\n",
    "        await asyncio.sleep(3)\n",
    "        print(\"Processed:\", job)\n",
    "        queue.task_done()\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def start_workers():\n",
    "    for _ in range(2):\n",
    "        asyncio.create_task(worker())\n",
    "\n",
    "@app.post(\"/submit\")\n",
    "async def submit_job(data: str):\n",
    "    await queue.put(data)\n",
    "    return {\"status\": \"queued\"}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Async Worker with LLM Tasks\n",
    "\n",
    "```python\n",
    "async def llm_worker():\n",
    "    while True:\n",
    "        prompt = await queue.get()\n",
    "        result = await llm.ainvoke(prompt)\n",
    "        store(result)\n",
    "        queue.task_done()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Distributed Async Workers (Production Pattern)\n",
    "\n",
    "```\n",
    "FastAPI → Redis / RabbitMQ → Worker Fleet → Database / LLM\n",
    "```\n",
    "\n",
    "#### Example (Conceptual)\n",
    "\n",
    "```python\n",
    "@celery.task\n",
    "def process_job(data):\n",
    "    llm.invoke(data)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Scaling Strategy\n",
    "\n",
    "| Layer   | Scaling      |\n",
    "| ------- | ------------ |\n",
    "| Workers | Horizontal   |\n",
    "| Queue   | Distributed  |\n",
    "| LLM     | Rate limited |\n",
    "| Storage | Sharded      |\n",
    "\n",
    "---\n",
    "\n",
    "### Mental Model\n",
    "\n",
    "```\n",
    "Async Workers = Factory workers processing jobs from a conveyor belt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* Enable concurrency without blocking\n",
    "* Essential for scalable AI systems\n",
    "* Combine asyncio for I/O + worker queues for throughput\n",
    "* Production systems use external queues and worker pools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2872bf75",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
