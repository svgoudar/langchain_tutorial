{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e0214a",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## WebSockets —\n",
    "\n",
    "\n",
    "**WebSocket** is a persistent, full-duplex communication protocol that allows **bi-directional real-time data exchange** between client and server over a single TCP connection.\n",
    "\n",
    "It enables:\n",
    "\n",
    "* Live chat systems\n",
    "* Real-time dashboards\n",
    "* Streaming LLM responses\n",
    "* Multiplayer applications\n",
    "* Collaborative tools\n",
    "\n",
    "---\n",
    "\n",
    "### Where WebSockets Fit in the Architecture\n",
    "\n",
    "```\n",
    "Client ↔ WebSocket Server ↔ LLM / Database / Services\n",
    "```\n",
    "\n",
    "Unlike HTTP, the connection remains open.\n",
    "\n",
    "---\n",
    "\n",
    "### Why WebSockets for LLM Systems\n",
    "\n",
    "* Low latency streaming\n",
    "* Two-way communication\n",
    "* Supports long conversations\n",
    "* Efficient for continuous updates\n",
    "\n",
    "---\n",
    "\n",
    "### FastAPI WebSocket Server\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI, WebSocket\n",
    "import asyncio\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.websocket(\"/ws\")\n",
    "async def websocket_endpoint(ws: WebSocket):\n",
    "    await ws.accept()\n",
    "\n",
    "    while True:\n",
    "        message = await ws.receive_text()\n",
    "        await ws.send_text(f\"Echo: {message}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Browser Client Example\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```html\n",
    "<script>\n",
    "const ws = new WebSocket(\"ws://localhost:8000/ws\");\n",
    "\n",
    "ws.onopen = () => console.log(\"Connected\");\n",
    "\n",
    "ws.onmessage = (event) => console.log(\"Received:\", event.data);\n",
    "\n",
    "ws.send(\"Hello Server\");\n",
    "</script>\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### WebSocket + LLM Streaming\n",
    "\n",
    "#### Demonstration\n",
    "\n",
    "```python\n",
    "@app.websocket(\"/chat\")\n",
    "async def chat(ws: WebSocket):\n",
    "    await ws.accept()\n",
    "\n",
    "    prompt = await ws.receive_text()\n",
    "    \n",
    "    async for chunk in llm.astream(prompt):\n",
    "        await ws.send_text(chunk.content)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Scaling WebSockets\n",
    "\n",
    "```\n",
    "Load Balancer → WebSocket Servers → Redis Pub/Sub → Workers\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### WebSocket vs SSE\n",
    "\n",
    "| Feature    | WebSocket   | SSE                      |\n",
    "| ---------- | ----------- | ------------------------ |\n",
    "| Direction  | Two-way     | Server → Client          |\n",
    "| Complexity | Higher      | Lower                    |\n",
    "| Use cases  | Chat, games | Streaming, notifications |\n",
    "\n",
    "---\n",
    "\n",
    "### Mental Model\n",
    "\n",
    "```\n",
    "WebSocket = Permanent phone call between client and server\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* Enables true real-time systems\n",
    "* Best for interactive AI applications\n",
    "* More complex than SSE but more powerful\n",
    "* Essential for chat-style LLM interfaces"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
