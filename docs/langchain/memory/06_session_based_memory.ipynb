{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af0c3cc",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Session-Based Memory\n",
    "\n",
    "### What Is Session-Based Memory\n",
    "\n",
    "**Session-based memory** stores and retrieves conversation context **per user session**.\n",
    "Each session has its **own isolated memory**, ensuring that conversations do not leak across users or browser sessions.\n",
    "\n",
    "In LLM systems, session-based memory is a **scoping mechanism**, not a memory algorithm itself.\n",
    "\n",
    "```\n",
    "Session ID → Memory Instance → Conversation Context\n",
    "```\n",
    "\n",
    "It is commonly implemented using:\n",
    "\n",
    "* Conversation memory (buffer / summary / window)\n",
    "* A session key (session_id, user_id, chat_id)\n",
    "* External storage (Redis, DB, in-process dict)\n",
    "\n",
    "---\n",
    "\n",
    "### Why Session-Based Memory Is Required\n",
    "\n",
    "Without session-based memory:\n",
    "\n",
    "* All users share the same context\n",
    "* Conversations overwrite each other\n",
    "* Multi-user chatbots break\n",
    "\n",
    "With session-based memory:\n",
    "\n",
    "* Each user gets a private context\n",
    "* Parallel chats are supported\n",
    "* Stateful UX is possible\n",
    "\n",
    "---\n",
    "\n",
    "### How Session-Based Memory Works\n",
    "\n",
    "1. Client sends a request with `session_id`\n",
    "2. Backend maps `session_id → memory object`\n",
    "3. LLM uses only that memory\n",
    "4. Memory is updated and stored back\n",
    "\n",
    "```\n",
    "User A (session_1) → Memory A\n",
    "User B (session_2) → Memory B\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Architecture View\n",
    "\n",
    "![Image](https://www.cognee.ai/content/blog/posts/from-demo-to-production-1/atkinson.png?utm_source=chatgpt.com)\n",
    "\n",
    "![Image](https://miro.medium.com/v2/resize%3Afit%3A1400/1%2A1EbvDX7oUEQuzKyQ0a2AiA.png?utm_source=chatgpt.com)\n",
    "\n",
    "![Image](https://miro.medium.com/v2/resize%3Afit%3A1400/1%2AKvbtCxuppbszOwcTFlS_Rw.png?utm_source=chatgpt.com)\n",
    "\n",
    "---\n",
    "\n",
    "### Session-Based Memory Using LangChain (In-Memory)\n",
    "\n",
    "Using LangChain.\n",
    "\n",
    "#### Session → Memory Store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8727834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sangouda\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "\n",
    "session_store = {}\n",
    "\n",
    "def get_memory(session_id: str):\n",
    "    if session_id not in session_store:\n",
    "        session_store[session_id] = ConversationBufferMemory()\n",
    "    return session_store[session_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102343c4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Each session gets its **own ConversationBufferMemory**.\n",
    "\n",
    "---\n",
    "\n",
    "### Attach Session Memory to a Chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b80e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import ConversationChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "def get_conversation(session_id: str):\n",
    "    memory = get_memory(session_id)\n",
    "    return ConversationChain(llm=llm, memory=memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b9ff72",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Demonstration (Two Sessions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c167a142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangouda\\AppData\\Local\\Temp\\ipykernel_32856\\518817146.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  session_store[session_id] = ConversationBufferMemory()\n",
      "C:\\Users\\sangouda\\AppData\\Local\\Temp\\ipykernel_32856\\767081169.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use `langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  return ConversationChain(llm=llm, memory=memory)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" You reported not being able to access email. Is this a recurring issue or is it the first time it's happened?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_a = get_conversation(\"session_A\")\n",
    "chat_b = get_conversation(\"session_B\")\n",
    "\n",
    "chat_a.predict(input=\"My VPN is not working\")\n",
    "chat_b.predict(input=\"I cannot access email\")\n",
    "\n",
    "chat_a.predict(input=\"What issue did I report?\")\n",
    "chat_b.predict(input=\"What issue did I report?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bce744",
   "metadata": {},
   "source": [
    "**Outputs**\n",
    "\n",
    "```\n",
    "Session A → You reported a VPN issue.\n",
    "Session B → You reported an email access issue.\n",
    "```\n",
    "\n",
    "This proves **memory isolation per session**.\n",
    "\n",
    "---\n",
    "\n",
    "### Session-Based Memory with FastAPI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42579e02",
   "metadata": {},
   "source": [
    "```python\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    session_id: str\n",
    "    message: str\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "def chat(req: ChatRequest):\n",
    "    conversation = get_conversation(req.session_id)\n",
    "    response = conversation.predict(input=req.message)\n",
    "    return {\"response\": response}\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "* Frontend sends `session_id`\n",
    "* Backend restores correct memory\n",
    "* Chat remains stateful\n",
    "\n",
    "---\n",
    "\n",
    "### Session-Based Memory with Redis (Production)\n",
    "\n",
    "```python\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory.chat_message_histories import RedisChatMessageHistory\n",
    "\n",
    "def get_memory(session_id):\n",
    "    history = RedisChatMessageHistory(\n",
    "        session_id=session_id,\n",
    "        url=\"redis://localhost:6379\"\n",
    "    )\n",
    "    return ConversationBufferMemory(chat_memory=history)\n",
    "```\n",
    "\n",
    "Benefits:\n",
    "\n",
    "* Survives restarts\n",
    "* Horizontally scalable\n",
    "* Multi-instance safe\n",
    "\n",
    "---\n",
    "\n",
    "### What Session-Based Memory Is NOT\n",
    "\n",
    "| Misconception    | Reality                      |\n",
    "| ---------------- | ---------------------------- |\n",
    "| A memory type    | It is a **scoping strategy** |\n",
    "| Long-term memory | Session-scoped               |\n",
    "| Semantic recall  | Depends on memory used       |\n",
    "| Model feature    | Application-level            |\n",
    "\n",
    "---\n",
    "\n",
    "### Session-Based Memory vs Memory Types\n",
    "\n",
    "| Aspect  | Session-Based | Memory Type      |\n",
    "| ------- | ------------- | ---------------- |\n",
    "| Purpose | Isolation     | Recall strategy  |\n",
    "| Scope   | Per user/chat | Global           |\n",
    "| Example | session_id    | Buffer / Summary |\n",
    "| Storage | Dict / Redis  | Text / Vectors   |\n",
    "\n",
    "They are **orthogonal concepts**.\n",
    "\n",
    "---\n",
    "\n",
    "### Real-World Use Case\n",
    "\n",
    "**Production IT Support Chatbot**\n",
    "\n",
    "* session_id per browser tab\n",
    "* Window memory for recent steps\n",
    "* Entity memory for user environment\n",
    "* Vector memory for long-term recall\n",
    "\n",
    "All scoped by **session**.\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "* Generate session IDs client-side\n",
    "* Expire idle sessions\n",
    "* Use Redis or DB in production\n",
    "* Never share memory across sessions\n",
    "* Log session → tool usage\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* Session-based memory ensures **conversation isolation**\n",
    "* It wraps any memory type\n",
    "* Mandatory for multi-user systems\n",
    "* Foundation for scalable chat applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
