{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5014a68",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory\n",
    "\n",
    "\n",
    "**ConversationSummaryMemory** is a **compressed conversation memory** mechanism that **summarizes past interactions** instead of storing the full chat transcript.\n",
    "The summary is continuously updated using an LLM and injected into future prompts, enabling **long-running conversations with bounded token usage**.\n",
    "\n",
    "Provided by LangChain.\n",
    "\n",
    "```\n",
    "User ↔ Assistant\n",
    "   ↓\n",
    "Conversation History\n",
    "   ↓ (LLM summarization)\n",
    "Running Summary\n",
    "   ↓\n",
    "Prompt (with compact context)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Why ConversationSummaryMemory Exists\n",
    "\n",
    "ConversationBufferMemory replays the entire chat, which:\n",
    "\n",
    "* Increases token usage\n",
    "* Raises cost\n",
    "* Hits context window limits\n",
    "\n",
    "ConversationSummaryMemory solves this by:\n",
    "\n",
    "* Keeping **only the essence**\n",
    "* Maintaining **conversation continuity**\n",
    "* Scaling to long sessions\n",
    "\n",
    "---\n",
    "\n",
    "### How ConversationSummaryMemory Works Internally\n",
    "\n",
    "1. Conversation progresses\n",
    "2. When memory updates, an LLM:\n",
    "\n",
    "   * Reads recent messages\n",
    "   * Updates a running summary\n",
    "3. Old raw messages are discarded\n",
    "4. Only the summary is passed forward\n",
    "\n",
    "Example evolving summary:\n",
    "\n",
    "```\n",
    "User reported VPN issue on Windows.\n",
    "Assistant suggested basic troubleshooting.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Architecture View\n",
    "\n",
    "![Image](https://dezyre.gumlet.io/images/blog/langchain-memory/Types_of_Langchain_Memory.webp?dpr=2.6\\&w=376\\&utm_source=chatgpt.com)\n",
    "\n",
    "![Image](https://towardsdatascience.com/wp-content/uploads/2024/11/1ncfjCpCN8XqYBj7wyZziow.png?utm_source=chatgpt.com)\n",
    "\n",
    "![Image](https://www.vasinov.com/images/adding-memory-to-gpt-models/gpt-memory-2.png?utm_source=chatgpt.com)\n",
    "\n",
    "---\n",
    "\n",
    "### Basic Demonstration (LangChain)\n",
    "\n",
    "#### Initialize Summary Memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "761c9872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangouda\\AppData\\Local\\Temp\\ipykernel_32036\\3387790345.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.memory import ConversationSummaryMemory\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d55adf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Attach Memory to a Conversation Chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4658201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangouda\\AppData\\Local\\Temp\\ipykernel_32036\\1074503449.py:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use `langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.chains import ConversationChain\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347727e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### Run a Long Conversation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be169dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' It seems like you are experiencing issues with your VPN on Windows 11. Specifically, it keeps disconnecting every 5 minutes. Is that correct?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"My VPN is not working on Windows 11\")\n",
    "conversation.predict(input=\"It disconnects every 5 minutes\")\n",
    "conversation.predict(input=\"I already tried restarting\")\n",
    "conversation.predict(input=\"What issue am I facing?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1858cdb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Output**\n",
    "\n",
    "```\n",
    "You are facing a VPN connectivity issue on Windows 11 that disconnects frequently, despite restarting.\n",
    "```\n",
    "\n",
    "The model recalls this **from the summary**, not raw history.\n",
    "\n",
    "---\n",
    "\n",
    "### Inspecting the Stored Summary\n",
    "\n",
    "```python\n",
    "print(memory.buffer)\n",
    "```\n",
    "\n",
    "Example summary:\n",
    "\n",
    "```\n",
    "User has a VPN connectivity issue on Windows 11 with frequent disconnections.\n",
    "Restarting did not resolve the issue.\n",
    "```\n",
    "\n",
    "This replaces dozens of prior messages.\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt Injection Mechanism\n",
    "\n",
    "Instead of replaying full chat history, the prompt contains:\n",
    "\n",
    "```\n",
    "System: You are a helpful assistant.\n",
    "\n",
    "Conversation Summary:\n",
    "User has a VPN connectivity issue on Windows 11 with frequent disconnections.\n",
    "\n",
    "Human: What issue am I facing?\n",
    "AI:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Strengths of ConversationSummaryMemory\n",
    "\n",
    "* Bounded token usage\n",
    "* Suitable for long sessions\n",
    "* Lower cost than buffer memory\n",
    "* Maintains conversational continuity\n",
    "\n",
    "---\n",
    "\n",
    "### Limitations\n",
    "\n",
    "| Limitation     | Explanation                          |\n",
    "| -------------- | ------------------------------------ |\n",
    "| Loss of detail | Fine-grained info may be dropped     |\n",
    "| Summary drift  | Errors propagate if summary is wrong |\n",
    "| LLM dependency | Needs model calls to summarize       |\n",
    "| Not queryable  | No semantic recall of specifics      |\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use ConversationSummaryMemory\n",
    "\n",
    "Use it when:\n",
    "\n",
    "* Sessions are long-running\n",
    "* Cost control matters\n",
    "* Exact phrasing is not critical\n",
    "* You need conversational continuity\n",
    "\n",
    "Avoid it when:\n",
    "\n",
    "* Exact wording matters\n",
    "* You need factual traceability\n",
    "* Auditing or compliance is required\n",
    "\n",
    "---\n",
    "\n",
    "### Comparison with Other Memory Types\n",
    "\n",
    "| Memory Type               | Stored Data | Token Growth | Best Use         |\n",
    "| ------------------------- | ----------- | ------------ | ---------------- |\n",
    "| ConversationBufferMemory  | Full chat   | High         | Short chats      |\n",
    "| ConversationSummaryMemory | Summary     | Low          | Long chats       |\n",
    "| VectorStoreMemory         | Embeddings  | Low          | Semantic recall  |\n",
    "| Redis / DB Memory         | Structured  | Low          | Production scale |\n",
    "\n",
    "---\n",
    "\n",
    "### Real-World Use Case\n",
    "\n",
    "**Production IT Support Assistant**\n",
    "\n",
    "* Long user sessions\n",
    "* Multi-step troubleshooting\n",
    "* Needs continuity without token explosion\n",
    "* Summary memory maintains context efficiently\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* ConversationSummaryMemory stores **compressed context**\n",
    "* It scales better than buffer memory\n",
    "* Ideal for long-running conversational agents\n",
    "* Often combined with vector or database memory for precision\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
