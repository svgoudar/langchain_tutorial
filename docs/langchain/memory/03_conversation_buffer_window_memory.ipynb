{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cddbac20",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## ConversationBufferWindowMemory \n",
    "\n",
    "\n",
    "**ConversationBufferWindowMemory** stores **only the last *N* turns** of a conversation (a sliding window) and discards older messages.\n",
    "It preserves **recent context** while keeping **token usage bounded**.\n",
    "\n",
    "Provided by LangChain.\n",
    "\n",
    "```\n",
    "User ↔ Assistant\n",
    "   ↓\n",
    "Last N Messages (Window)\n",
    "   ↓\n",
    "Prompt (recent context only)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Why ConversationBufferWindowMemory Is Needed\n",
    "\n",
    "* Full buffer memory grows unbounded\n",
    "* Summary memory may lose details\n",
    "* Many tasks only need **recent context**\n",
    "\n",
    "This memory is a **middle ground**:\n",
    "\n",
    "* Keeps verbatim messages\n",
    "* Limits history size\n",
    "* Avoids summarization overhead\n",
    "\n",
    "---\n",
    "\n",
    "### How It Works Internally\n",
    "\n",
    "1. Each user/assistant message is appended\n",
    "2. If total messages exceed the window size:\n",
    "\n",
    "   * Oldest messages are removed\n",
    "3. Only the most recent **k turns** are injected into the prompt\n",
    "\n",
    "Example with `k=2`:\n",
    "\n",
    "```\n",
    "[Kept]\n",
    "Human: It disconnects every 5 minutes\n",
    "AI: Try checking network drivers\n",
    "Human: I already updated them\n",
    "AI: Thanks for confirming\n",
    "\n",
    "[Discarded]\n",
    "Earlier conversation…\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Architecture View\n",
    "\n",
    "![Image](https://media.geeksforgeeks.org/wp-content/uploads/20250926150233170952/architecture_of_conversation_buffer_window_memory.webp?utm_source=chatgpt.com)\n",
    "\n",
    "![Image](https://media.geeksforgeeks.org/wp-content/uploads/20250925181819723356/features_of_conversation_buffer_memory.webp?utm_source=chatgpt.com)\n",
    "\n",
    "![Image](https://timwappat.info/content/images/2024/12/Context-Window-Summary-1.jpg?utm_source=chatgpt.com)\n",
    "\n",
    "---\n",
    "\n",
    "### Basic Demonstration (LangChain)\n",
    "\n",
    "#### Initialize Window Memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c4eb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sangouda\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangouda\\AppData\\Local\\Temp\\ipykernel_22704\\1644586139.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=2)\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeae234",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here, `k=2` means:\n",
    "\n",
    "* Keep the **last 2 conversational turns**\n",
    "* A turn = Human + AI messages\n",
    "\n",
    "---\n",
    "\n",
    "#### Attach Memory to a Conversation Chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae6e8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangouda\\AppData\\Local\\Temp\\ipykernel_22704\\2335344415.py:6: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use `langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.chains import ConversationChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b14492",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Run a Multi-Turn Conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "792e3609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' You mentioned restarting your device and reconnecting to the VPN. Sometimes, simply disconnecting and reconnecting to the VPN can also help resolve connectivity issues. Additionally, checking for software updates and reaching out to your VPN provider for assistance are also steps you have taken.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"My VPN is not working\")\n",
    "conversation.predict(input=\"It disconnects every 5 minutes\")\n",
    "conversation.predict(input=\"I already tried restarting\")\n",
    "conversation.predict(input=\"What did I try earlier?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f24c0a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Expected Output**\n",
    "\n",
    "```\n",
    "You tried restarting the VPN.\n",
    "```\n",
    "\n",
    "The model recalls this because it is **within the window**.\n",
    "\n",
    "If the window were exceeded, earlier details would be forgotten.\n",
    "\n",
    "---\n",
    "\n",
    "### Inspecting the Memory Buffer\n",
    "\n",
    "```python\n",
    "print(memory.buffer)\n",
    "```\n",
    "\n",
    "Example buffer (k=2):\n",
    "\n",
    "```\n",
    "Human: It disconnects every 5 minutes\n",
    "AI: Have you tried restarting?\n",
    "\n",
    "Human: I already tried restarting\n",
    "AI: Thanks for confirming.\n",
    "```\n",
    "\n",
    "Older messages are **no longer present**.\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt Injection Mechanism\n",
    "\n",
    "The prompt includes only recent messages:\n",
    "\n",
    "```\n",
    "System: You are a helpful assistant.\n",
    "\n",
    "Recent Conversation:\n",
    "Human: I already tried restarting\n",
    "AI: Thanks for confirming.\n",
    "\n",
    "Human: What did I try earlier?\n",
    "AI:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Strengths of ConversationBufferWindowMemory\n",
    "\n",
    "* Fixed token usage\n",
    "* No summarization cost\n",
    "* Preserves exact wording (recent)\n",
    "* Simple and predictable behavior\n",
    "\n",
    "---\n",
    "\n",
    "### Limitations\n",
    "\n",
    "| Limitation            | Explanation                |\n",
    "| --------------------- | -------------------------- |\n",
    "| Forgets older context | Hard cutoff                |\n",
    "| No long-term memory   | Not suitable alone         |\n",
    "| Manual tuning         | Window size must be chosen |\n",
    "| No semantic recall    | Exact text only            |\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use ConversationBufferWindowMemory\n",
    "\n",
    "Use it when:\n",
    "\n",
    "* Only recent context matters\n",
    "* Conversations are task-focused\n",
    "* You want low cost and simplicity\n",
    "* You need deterministic memory behavior\n",
    "\n",
    "Avoid it when:\n",
    "\n",
    "* Long-term context is required\n",
    "* Earlier facts must persist\n",
    "* Compliance or audit trails are needed\n",
    "\n",
    "---\n",
    "\n",
    "### Comparison with Other Memory Types\n",
    "\n",
    "| Memory Type                    | Stores       | Token Growth | Best Use        |\n",
    "| ------------------------------ | ------------ | ------------ | --------------- |\n",
    "| ConversationBufferMemory       | Full chat    | High         | Short chats     |\n",
    "| ConversationBufferWindowMemory | Last N turns | Fixed        | Task-based chat |\n",
    "| ConversationSummaryMemory      | Summary      | Low          | Long sessions   |\n",
    "| VectorStoreMemory              | Embeddings   | Low          | Semantic recall |\n",
    "\n",
    "---\n",
    "\n",
    "### Real-World Use Case\n",
    "\n",
    "**IT Support Assistant**\n",
    "\n",
    "* Recent troubleshooting steps matter most\n",
    "* Old greetings are irrelevant\n",
    "* Window memory keeps the agent focused\n",
    "* Often combined with vector or DB memory\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* ConversationBufferWindowMemory is a **sliding-window memory**\n",
    "* Keeps recent turns verbatim\n",
    "* Controls cost and context size\n",
    "* Ideal for task-oriented conversational agents\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
