{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d22b7a5",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Long-Term vs Short-Term Memory \n",
    "\n",
    "**Short-term memory** stores **immediate conversational context** required to answer follow-up questions within the same interaction flow.\n",
    "It is **temporary, fast, and limited in size**.\n",
    "\n",
    "Typical implementations:\n",
    "\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationSummaryMemory\n",
    "\n",
    "Provided by LangChain.\n",
    "\n",
    "```\n",
    "Recent Conversation\n",
    "   ↓\n",
    "Short-Term Memory\n",
    "   ↓\n",
    "Prompt Context\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### What Is Long-Term Memory\n",
    "\n",
    "**Long-term memory** stores **persistent knowledge** across conversations, sessions, or even days/weeks.\n",
    "It is **retrievable by relevance**, not by time.\n",
    "\n",
    "Typical implementations:\n",
    "\n",
    "* VectorStore-backed memory\n",
    "* Entity memory\n",
    "* Database / Redis memory\n",
    "\n",
    "```\n",
    "Facts / Events / Preferences\n",
    "   ↓\n",
    "Long-Term Storage\n",
    "   ↓ (semantic or key lookup)\n",
    "Relevant Context\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Differences at a Glance\n",
    "\n",
    "| Aspect   | Short-Term Memory   | Long-Term Memory      |\n",
    "| -------- | ------------------- | --------------------- |\n",
    "| Lifetime | Single conversation | Across sessions       |\n",
    "| Size     | Small               | Large                 |\n",
    "| Recall   | Sequential / recent | Semantic / factual    |\n",
    "| Cost     | Low                 | Medium                |\n",
    "| Purpose  | Dialogue continuity | Knowledge persistence |\n",
    "\n",
    "---\n",
    "\n",
    "### Architecture View (Together)\n",
    "\n",
    "![Image](https://pub.mdpi-res.com/information/information-16-00251/article_deploy/html/images/information-16-00251-ag.png?1742545416=\\&utm_source=chatgpt.com)\n",
    "\n",
    "![Image](https://www.researchgate.net/publication/330146405/figure/fig1/AS%3A740703420289028%401553608865987/Block-diagram-of-hybrid-memory-architecture-of-XMT-The-serial-portion-comprises-the.png?utm_source=chatgpt.com)\n",
    "\n",
    "![Image](https://framerusercontent.com/images/1dnPyEubTTivZJXo8nRbdQRpds.png?height=1264\\&width=2000\\&utm_source=chatgpt.com)\n",
    "\n",
    "```\n",
    "User Input\n",
    "   ↓\n",
    "Short-Term Memory (recent chat)\n",
    "   ↓\n",
    "Long-Term Memory (relevant facts)\n",
    "   ↓\n",
    "LLM Response\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Short-Term Memory — Demonstration\n",
    "\n",
    "### Short-Term Memory Using ConversationBufferWindowMemory\n",
    "\n",
    "```python\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "short_term_memory = ConversationBufferWindowMemory(k=2)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=short_term_memory\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Short-Term Memory in Action\n",
    "\n",
    "```python\n",
    "conversation.predict(input=\"My VPN is not working\")\n",
    "conversation.predict(input=\"It disconnects every 5 minutes\")\n",
    "conversation.predict(input=\"What issue did I mention?\")\n",
    "```\n",
    "\n",
    "**Output**\n",
    "\n",
    "```\n",
    "You mentioned that your VPN disconnects every 5 minutes.\n",
    "```\n",
    "\n",
    "Only **recent turns** are remembered.\n",
    "\n",
    "---\n",
    "\n",
    "## Long-Term Memory — Demonstration\n",
    "\n",
    "### Long-Term Memory Using Vector Store\n",
    "\n",
    "Using Chroma:\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"long_term_memory\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "long_term_memory = VectorStoreRetrieverMemory(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Long-Term Memory in Action\n",
    "\n",
    "```python\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=long_term_memory\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"I use Windows 11 and my VPN drops often\")\n",
    "conversation.predict(input=\"What OS do I usually work on?\")\n",
    "```\n",
    "\n",
    "**Output**\n",
    "\n",
    "```\n",
    "You usually work on Windows 11.\n",
    "```\n",
    "\n",
    "This works **even after many interactions**, because recall is **semantic**, not positional.\n",
    "\n",
    "---\n",
    "\n",
    "## Combining Short-Term + Long-Term Memory\n",
    "\n",
    "### Hybrid Memory Pattern (Recommended)\n",
    "\n",
    "```python\n",
    "from langchain.memory import CombinedMemory\n",
    "\n",
    "memory = CombinedMemory(memories=[\n",
    "    short_term_memory,\n",
    "    long_term_memory\n",
    "])\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Hybrid Memory Behavior\n",
    "\n",
    "* Short-term memory → recent troubleshooting steps\n",
    "* Long-term memory → OS, device, recurring issues\n",
    "\n",
    "```\n",
    "User: It’s still disconnecting\n",
    "LLM:\n",
    "• Uses short-term memory → “still”\n",
    "• Uses long-term memory → “VPN on Windows 11”\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Real-World Use Case\n",
    "\n",
    "**Production IT Support Assistant**\n",
    "\n",
    "* Short-term memory:\n",
    "\n",
    "  * Current troubleshooting flow\n",
    "* Long-term memory:\n",
    "\n",
    "  * User OS, device, recurring incidents\n",
    "  * Historical preferences\n",
    "\n",
    "This mirrors **human cognition**.\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use What\n",
    "\n",
    "**Use short-term memory when:**\n",
    "\n",
    "* Context is immediate\n",
    "* Tasks are linear\n",
    "* Cost must be minimal\n",
    "\n",
    "**Use long-term memory when:**\n",
    "\n",
    "* Personalization matters\n",
    "* Sessions span time\n",
    "* Facts must persist\n",
    "\n",
    "---\n",
    "\n",
    "### Best-Practice Memory Strategy\n",
    "\n",
    "| Layer          | Memory Type     |\n",
    "| -------------- | --------------- |\n",
    "| Immediate      | Buffer / Window |\n",
    "| Conversational | Summary         |\n",
    "| Knowledge      | Vector / Entity |\n",
    "| Persistence    | DB / Redis      |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* Short-term memory handles **conversation flow**\n",
    "* Long-term memory handles **knowledge retention**\n",
    "* They solve different problems\n",
    "* Production systems **always combine both**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
